{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilyhahn/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as mp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.io import savemat, loadmat\n",
    "from scipy.stats import pointbiserialr\n",
    "from matplotlib.patches import Circle\n",
    "from sklearn import datasets, linear_model\n",
    "from scipy.stats import probplot, pearsonr\n",
    "from matplotlib.cbook import get_sample_data\n",
    "from pandas.plotting import lag_plot\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.preprocessing import scale \n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage,AnnotationBbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dACC_group=[]\n",
    "L_dlPFC_group=[]\n",
    "R_dlPFC_group=[]\n",
    "L_IFG_group=[]\n",
    "R_IFG_group=[]\n",
    "conflict_group=[]\n",
    "adapt_group=[]\n",
    "rt_group=[]\n",
    "\n",
    "dACC_group_hc=[]\n",
    "L_dlPFC_group_hc=[]\n",
    "R_dlPFC_group_hc=[]\n",
    "L_IFG_group_hc=[]\n",
    "R_IFG_group_hc=[]\n",
    "conflict_group_hc=[]\n",
    "adapt_group_hc=[]\n",
    "rt_group_hc=[]\n",
    "\n",
    "dACC_group_pts=[]\n",
    "L_dlPFC_group_pts=[]\n",
    "R_dlPFC_group_pts=[]\n",
    "L_IFG_group_pts=[]\n",
    "R_IFG_group_pts=[]\n",
    "conflict_group_pts=[]\n",
    "adapt_group_pts=[]\n",
    "rt_group_pts=[]\n",
    "\n",
    "raw_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/msit_mri_behav'\n",
    "preproc_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/completed'\n",
    "LSS_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG'\n",
    "LSS_estim_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG_estim'\n",
    "censor_dir='/Users/emilyhahn/projects/msit_modeling/censor_data'\n",
    "df=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],\\\n",
    "                 'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],\\\n",
    "                 'rt':[],'conflict':[],'adapt':[],'sequence':[],'rank':[]})\n",
    "stim_blocks_path=os.path.join(raw_behav_dir,'stimuli_block.txt')\n",
    "stim_blocks=pd.read_csv(stim_blocks_path,names=['sequence'])\n",
    "rank_path=os.path.join(raw_behav_dir,'rank.txt')\n",
    "rank=pd.read_csv(rank_path,names=['rank'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SUBJ_LIST = ['hc001','hc002','hc003','hc004','hc005','hc006','hc009','hc010','hc011',\\\n",
    "#              'hc012','hc014','hc015','hc017','hc018','hc019','hc021','hc023','hc028',\\\n",
    "#              'hc031','hc032','hc033','hc034','hc036','hc038','hc042']\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# SUBJ_LIST = ['pp001','pp002','pp003','pp004','pp005','pp006','pp007','pp008',\\\n",
    "#              'pp010','pp011','pp012','pp013','pp015','pp016']\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "SUBJ_LIST = ['hc001','hc002','hc003','hc004','hc005','hc006','hc009','hc010','hc011',\\\n",
    "             'hc012','hc014','hc015','hc017','hc018','hc019','hc021','hc023','hc028',\\\n",
    "             'hc031','hc032','hc033','hc034','hc036','hc038','hc042','pp001','pp002',\\\n",
    "             'pp003','pp004','pp005','pp006','pp007','pp008','pp010','pp011','pp012',\\\n",
    "             'pp013','pp015','pp016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions - Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(arr): return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "def generate_roi_vars(roi_file,region,var):\n",
    "    with open(roi_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            line=float(line)\n",
    "            if -5<line<5 and line!=0:\n",
    "                region.append(line)\n",
    "            else:\n",
    "                region.append('NaN')\n",
    "#                 print \"%s beta exlcuded for %s\" % (line,roi_file)\n",
    "    return\n",
    "def censor_tps(censor_file,censor_var,var):\n",
    "    with open(censor_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            censor_var.append(line)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Indiv and Group Data - SS output, ROI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for SUBJ in SUBJ_LIST:\n",
    "    bcsv=glob.glob(os.path.join(raw_behav_dir,'%s*' % SUBJ))\n",
    "    for file in bcsv:\n",
    "        conflict=[]\n",
    "        adapt=[]\n",
    "        dACC=[]\n",
    "        L_IFG=[]\n",
    "        R_IFG=[]\n",
    "        L_dlPFC=[]\n",
    "        R_dlPFC=[]\n",
    "        cond=[]\n",
    "        trial=[]\n",
    "        acc=[]\n",
    "        censor=[]\n",
    "        rank=[]\n",
    "        stim_blocks=[]\n",
    "        rt=[]\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        stim_blocks_path=os.path.join(raw_behav_dir,'stimuli_block.txt')\n",
    "        stim_blocks=pd.read_csv(stim_blocks_path,names=['sequence'])\n",
    "\n",
    "        rank_path=os.path.join(raw_behav_dir,'rank.txt')\n",
    "        rank=pd.read_csv(rank_path,names=['rank'])\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        b=pd.read_csv(file)\n",
    "        b['sequence'] = stim_blocks\n",
    "        b['rank'] = rank \n",
    "        trials = b[ b['Stimuli'] != '+' ]\n",
    "        trials=trials[1:-2]\n",
    "        trials_df=pd.DataFrame({'sequence':trials['sequence'],'rank':trials['rank']})\n",
    "        trials_df=trials_df.reset_index(drop=True)\n",
    "        #---------------------------------##\n",
    "        ## Configure SS variables\n",
    "        #---------------------------------## \n",
    "        mat = loadmat(os.path.join(preproc_behav_dir,'%s_msit_ss_iter250.mat') % SUBJ)\n",
    "        #---------------------------------##\n",
    "        ss_outputs_xsmt = np.expand_dims(np.array([np.concatenate(arr) \\\n",
    "                                    for arr in mat['XSmt']]).squeeze(),1)\n",
    "        ss_xsmt = normalize(ss_outputs_xsmt.squeeze())\n",
    "        rt.extend([float(i) for i in np.array(mat['RT'].squeeze())])\n",
    "        conflict.extend([float(i[0]) for i in ss_xsmt])\n",
    "        adapt.extend([float(i[1]) for i in ss_xsmt])\n",
    "        acc.extend([float(i) for i in np.array(mat['Accuracy'].squeeze())])\n",
    "        trial.extend([float(i) for i in np.array(mat['Trial'].squeeze())])\n",
    "        cond.extend([float(i) for i in np.array(mat['Interference'].squeeze())])\n",
    "        #---------------------------------##\n",
    "        ## Configure ROI variables\n",
    "        #---------------------------------##\n",
    "        ## Load indiv ROI vars\n",
    "        file_1=os.path.join(LSS_dir,'%s.dACC_LSS_avg_file.1D' % SUBJ)\n",
    "        file_2=os.path.join(LSS_dir,'%s.L_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "        file_3=os.path.join(LSS_dir,'%s.R_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "        file_4=os.path.join(LSS_dir,'%s.L_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "        file_5=os.path.join(LSS_dir,'%s.R_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "        file_6=os.path.join(censor_dir,'msit.%s.msit_bsm.censor.1D' % SUBJ)\n",
    "        #---------------------------------##\n",
    "        ## Generate ROI variables\n",
    "        generate_roi_vars(file_1,dACC,\"dACC\")\n",
    "        generate_roi_vars(file_2,L_IFG,\"L_IFG\")\n",
    "        generate_roi_vars(file_3,R_IFG,\"R_IFG\")\n",
    "        generate_roi_vars(file_4,L_dlPFC,\"L_dlPFC\")\n",
    "        generate_roi_vars(file_5,R_dlPFC,\"R_dlPFC\")\n",
    "        censor_tps(file_6,censor,\"censor\")\n",
    "        #---------------------------------##\n",
    "        ## Determine group\n",
    "        s=[]\n",
    "        if 'hc' in SUBJ:\n",
    "            s.append(1)\n",
    "        elif 'pp' in SUBJ:\n",
    "            s.append(2)\n",
    "        GROUP_ARR=np.array([\"%s\" % s] * len(trial))\n",
    "        group=[i.strip('[]') for i in GROUP_ARR]\n",
    "        SUBJ_ARR=np.array([\"%s\" % SUBJ] * len(trial))\n",
    "        #---------------------------------## \n",
    "        ## Interpolate missing ROI + RT data points\n",
    "        dACC = normalize(pd.Series(dACC).astype(float).interpolate())\n",
    "        R_IFG = normalize(pd.Series(R_IFG).astype(float).interpolate())\n",
    "        L_IFG = normalize(pd.Series(L_IFG).astype(float).interpolate())\n",
    "        L_dlPFC = normalize(pd.Series(L_dlPFC).astype(float).interpolate())\n",
    "        R_dlPFC = normalize(pd.Series(R_dlPFC).astype(float).interpolate())\n",
    "        rt = normalize(pd.Series(rt).astype(float).interpolate())\n",
    "        #---------------------------------## \n",
    "        dACC_group.append(dACC)\n",
    "        L_dlPFC_group.append(L_dlPFC)\n",
    "        R_dlPFC_group.append(R_dlPFC)\n",
    "        L_IFG_group.append(L_IFG)\n",
    "        R_IFG_group.append(R_IFG)\n",
    "        conflict_group.append(conflict)\n",
    "        adapt_group.append(adapt)\n",
    "        rt_group.append(rt)\n",
    "        #---------------------------------##\n",
    "        if 'pp' in SUBJ_ARR[0]:\n",
    "            dACC_group_pts.append(dACC)\n",
    "            L_dlPFC_group_pts.append(L_dlPFC)\n",
    "            R_dlPFC_group_pts.append(R_dlPFC)\n",
    "            L_IFG_group_pts.append(L_IFG)\n",
    "            R_IFG_group_pts.append(R_IFG)\n",
    "            conflict_group_pts.append(conflict)\n",
    "            adapt_group_pts.append(adapt)\n",
    "            rt_group_pts.append(rt)\n",
    "        elif 'hc' in SUBJ_ARR[0]:\n",
    "            dACC_group_hc.append(dACC)\n",
    "            L_dlPFC_group_hc.append(L_dlPFC)\n",
    "            R_dlPFC_group_hc.append(R_dlPFC)\n",
    "            L_IFG_group_hc.append(L_IFG)\n",
    "            R_IFG_group_hc.append(R_IFG)\n",
    "            conflict_group_hc.append(conflict)\n",
    "            adapt_group_hc.append(adapt)  \n",
    "            rt_group_hc.append(rt)  \n",
    "        else:\n",
    "            \"REVIEW SUBJ ID: %s\" % SUBJ\n",
    "        ##---------------------------------##\n",
    "        ## Append subj data to master DF\n",
    "        ##---------------------------------##\n",
    "        df1=pd.DataFrame({\"group\":group,\"subject\":SUBJ_ARR,'rt':rt,'dACC':dACC,\\\n",
    "                          'L_IFG':L_IFG,'R_IFG':R_IFG,'L_dlPFC':L_dlPFC,\\\n",
    "                          'R_dlPFC':R_dlPFC,'trial':trial,'cond':cond,'acc':acc,\\\n",
    "                          'conflict':conflict,'adapt':adapt,\\\n",
    "                          'sequence':[i for i in trials_df['sequence']],\\\n",
    "                          'rank':[i for i in trials_df['rank']]})\n",
    "        df=df.append(df1)\n",
    "# ##---------------------------------##\n",
    "# ## Parse DFs into groups\n",
    "# ##---------------------------------##\n",
    "# df_hcs=df.where(df['group']=='1')\n",
    "# df_hcs=df_hcs.dropna()\n",
    "# df_pts=df.where(df['group']=='2')\n",
    "# df_pts=df_pts.dropna()\n",
    "# ##---------------------------------##\n",
    "# ## Compute means for ALL subjs\n",
    "# ##---------------------------------##\n",
    "# dACC_group_avg=np.mean(dACC_group, axis=0, dtype=np.float64)\n",
    "# L_IFG_group_avg=np.mean(L_IFG_group, axis=0, dtype=np.float64)\n",
    "# R_IFG_group_avg=np.mean(R_IFG_group, axis=0, dtype=np.float64)\n",
    "# L_dlPFC_group_avg=np.mean(L_dlPFC_group, axis=0, dtype=np.float64)\n",
    "# R_dlPFC_group_avg=np.mean(R_dlPFC_group, axis=0, dtype=np.float64)\n",
    "# conflict_group_avg=np.mean(conflict_group, axis=0, dtype=np.float64)\n",
    "# adapt_group_avg=np.mean(adapt_group, axis=0, dtype=np.float64)\n",
    "# rt_group_avg=np.mean(rt_group, axis=0, dtype=np.float64)\n",
    "# ##---------------------------------##\n",
    "# ## Compute means for HC subjs\n",
    "# ##---------------------------------##\n",
    "# dACC_group_hc_avg=np.mean(dACC_group_hc, axis=0, dtype=np.float64)\n",
    "# L_IFG_group_hc_avg=np.mean(L_IFG_group_hc, axis=0, dtype=np.float64)\n",
    "# R_IFG_group_hc_avg=np.mean(R_IFG_group_hc, axis=0, dtype=np.float64)\n",
    "# L_dlPFC_group_hc_avg=np.mean(L_dlPFC_group_hc, axis=0, dtype=np.float64)\n",
    "# R_dlPFC_group_hc_avg=np.mean(R_dlPFC_group_hc, axis=0, dtype=np.float64)\n",
    "# conflict_group_hc_avg=np.mean(conflict_group_hc, axis=0, dtype=np.float64)\n",
    "# adapt_group_hc_avg=np.mean(adapt_group_hc, axis=0, dtype=np.float64)\n",
    "# rt_group_hc_avg=np.mean(rt_group_hc, axis=0, dtype=np.float64)\n",
    "# ##---------------------------------##\n",
    "# ## Compute means for PTS subjs\n",
    "# ##---------------------------------##\n",
    "# dACC_group_pts_avg=np.mean(dACC_group_pts, axis=0, dtype=np.float64)\n",
    "# L_IFG_group_pts_avg=np.mean(L_IFG_group_pts, axis=0, dtype=np.float64)\n",
    "# R_IFG_group_pts_avg=np.mean(R_IFG_group_pts, axis=0, dtype=np.float64)\n",
    "# L_dlPFC_group_pts_avg=np.mean(L_dlPFC_group_pts, axis=0, dtype=np.float64)\n",
    "# R_dlPFC_group_pts_avg=np.mean(R_dlPFC_group_pts, axis=0, dtype=np.float64)\n",
    "# conflict_group_pts_avg=np.mean(conflict_group_pts, axis=0, dtype=np.float64)\n",
    "# adapt_group_pts_avg=np.mean(adapt_group_pts, axis=0, dtype=np.float64)\n",
    "# rt_group_pts_avg=np.mean(rt_group_pts, axis=0, dtype=np.float64)\n",
    "# ##---------------------------------##\n",
    "# ## Parse Data Frames\n",
    "# ##---------------------------------##\n",
    "# df_avg=pd.DataFrame({'rt':rt_group_avg,'dACC':dACC_group_avg,'L_IFG':L_IFG_group_avg,\\\n",
    "#                      'R_IFG':R_IFG_group_avg,'L_dlPFC':L_dlPFC_group_avg,\\\n",
    "#                      'R_dlPFC':R_dlPFC_group_avg,'trial':trial,'cond':cond,\\\n",
    "#                      'conflict':conflict_group_avg,'adapt':adapt_group_avg})\n",
    "# df_hcs_avg=pd.DataFrame({'rt':rt_group_hc_avg,'dACC':dACC_group_hc_avg,'L_IFG':L_IFG_group_hc_avg,\\\n",
    "#                      'R_IFG':R_IFG_group_hc_avg,'L_dlPFC':L_dlPFC_group_hc_avg,\\\n",
    "#                      'R_dlPFC':R_dlPFC_group_hc_avg,'trial':trial,'cond':cond,\\\n",
    "#                      'conflict':conflict_group_hc_avg,'adapt':adapt_group_hc_avg})\n",
    "# df_pts_avg=pd.DataFrame({'rt':rt_group_pts_avg,'dACC':dACC_group_pts_avg,'L_IFG':L_IFG_group_pts_avg,\\\n",
    "#                      'R_IFG':R_IFG_group_pts_avg,'L_dlPFC':L_dlPFC_group_pts_avg,\\\n",
    "#                      'R_dlPFC':R_dlPFC_group_pts_avg,'trial':trial,'cond':cond,\\\n",
    "#                      'conflict':conflict_group_pts_avg,'adapt':adapt_group_pts_avg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilyhahn/anaconda2/lib/python2.7/site-packages/statsmodels/regression/mixed_linear_model.py:2019: ConvergenceWarning: The MLE may be on the boundary of the parameter space.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Mixed Linear Model Regression Results\n",
      "=======================================================\n",
      "Model:            MixedLM Dependent Variable: dACC     \n",
      "No. Observations: 7560    Method:             REML     \n",
      "No. Groups:       39      Scale:              0.0380   \n",
      "Min. group size:  189     Likelihood:         1542.3950\n",
      "Max. group size:  378     Converged:          Yes      \n",
      "Mean group size:  193.8                                \n",
      "-------------------------------------------------------\n",
      "             Coef.  Std.Err.   z    P>|z| [0.025 0.975]\n",
      "-------------------------------------------------------\n",
      "Intercept     0.347    0.015 22.486 0.000  0.317  0.377\n",
      "rank          0.004    0.001  4.526 0.000  0.002  0.005\n",
      "cond          0.009    0.008  1.190 0.234 -0.006  0.024\n",
      "rank:cond    -0.001    0.001 -0.537 0.591 -0.003  0.002\n",
      "groups RE     0.008    0.010                           \n",
      "=======================================================\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dist_low is too large and would result in a negative variance. Try a smaller value.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0ffa2fe90481>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmixed_LM_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ALL SUBJS'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-0ffa2fe90481>\u001b[0m in \u001b[0;36mmixed_LM_rank\u001b[0;34m(df_type, sub_or_group)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         likev = mdf.profile_re(0, 're', dist_low=.001, dist_high=.01)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mlikev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile_re\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m're'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_low\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_low\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_high\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdist_high\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlikev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlikev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/emilyhahn/anaconda2/lib/python2.7/site-packages/statsmodels/regression/mixed_linear_model.pyc\u001b[0m in \u001b[0;36mprofile_re\u001b[0;34m(self, re_ix, vtype, num_low, dist_low, num_high, dist_high)\u001b[0m\n\u001b[1;32m   2514\u001b[0m         \u001b[0;31m# interest will be constrained.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2515\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlow\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2516\u001b[0;31m             raise ValueError(\"dist_low is too large and would result in a \"\n\u001b[0m\u001b[1;32m   2517\u001b[0m                              \"negative variance. Try a smaller value.\")\n\u001b[1;32m   2518\u001b[0m         \u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mru0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_low\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: dist_low is too large and would result in a negative variance. Try a smaller value."
     ]
    }
   ],
   "source": [
    "## Documentation on MLE plotting:\n",
    "## \"https://www.statsmodels.org/devel/_modules/statsmodels/regression/mixed_linear_model.html\"\n",
    "# import warnings\n",
    "# with warnings.catch_warnings():\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "def mixed_LM_rank(df_type,sub_or_group):\n",
    "    for beta in ['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']:\n",
    "        md = smf.mixedlm(\"%s ~ rank * cond\" % beta,data=df_type,groups='subject')\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        likev = mdf.profile_re(0, 're', dist_low=.001, dist_high=.01)\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.plot(likev[:,0], 2*likev[:,1])\n",
    "        plt.xlabel(\"Variance of random slope\", size=12)\n",
    "        plt.ylabel(\"-2 times profile log likelihood\", size=12)\n",
    "        plt.title(\"%s\" % beta)\n",
    "        plt.show()\n",
    "    return\n",
    "mixed_LM_rank(df,'ALL SUBJS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize SS variables, RT, Cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ss_rt_plots(df_type,sub_or_group):\n",
    "    ##---------------------------------##\n",
    "    ## Plot SS and Behvaior\n",
    "    ##---------------------------------##  \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sns.set_style(\"darkgrid\",{\"axes.facecolor\":\".85\"})\n",
    "    sns.set_context('paper', font_scale=2.25)\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ## Plot reaction time and trial timeseries\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    fig = plt.figure(figsize=(20,7))\n",
    "    ax = plt.subplot2grid((4,4),(1,0),colspan=3,rowspan=3)\n",
    "    ss_title=\"MSIT | %s\" % sub_or_group\n",
    "    colors = np.where(df_type[\"cond\"], 'firebrick', 'navy')\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ## Use when plotting indivs or groups (not averages)\n",
    "#     markers = np.where(df_type[\"acc\"],'o','x').squeeze()\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ax.plot(df_type[\"trial\"], df_type[\"rt\"], color='k', linewidth=2, alpha=0.4)\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    for x,y,c in zip(df_type['trial'], df_type[\"rt\"], colors): \n",
    "        ax.scatter(x,y,s=40,color=c)\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ## Use when plotting indivs or groups (not averages)\n",
    "#     for x,y,c,m in zip(df_type['trial'], df_type[\"rt\"], colors, markers): \n",
    "#         ax.scatter(x,y,s=40,marker=m,color=c)\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    for color, label in zip(['navy', 'firebrick'], ['C','I']): \n",
    "        ax.scatter([],[], s=60, color=color, label=label)\n",
    "    # Configure matplotlib.patch.Patch properties\n",
    "    props = dict(facecolor='white',alpha=0.5)\n",
    "    ax.text(1.03, 0.6, r'$\\bigcirc$ = Incongruent', transform=ax.transAxes, fontsize=18,\\\n",
    "        verticalalignment='top', bbox=props, color='firebrick')\n",
    "    ax.text(1.03, 0.4, r'$\\bigcirc$ = Congruent', transform=ax.transAxes, fontsize=18,\\\n",
    "        verticalalignment='top', bbox=props, color='navy')\n",
    "    ax.set_xlim(0,190)\n",
    "    ax.set_xlabel('Trial Number', fontsize=18)\n",
    "    ax.set_ylabel('Reaction Time', fontsize=18)\n",
    "    ax.set_title('%s' % ss_title,loc='center')\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ## Plot state space\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    line1,=ax.plot(df_type[\"trial\"],df_type[\"conflict\"],linewidth=2,alpha=0.7,color='firebrick',label='Conflict')\n",
    "    line2,=ax.plot(df_type[\"trial\"],df_type[\"adapt\"],linewidth=2,alpha=0.7,color='navy',label='Adapt')\n",
    "#     Conflict legend\n",
    "    first_legend = plt.legend(handles=[line1],loc=7, bbox_to_anchor=(1.175,0.95))\n",
    "    ax = plt.gca().add_artist(first_legend)\n",
    "#     Adaptation legend\n",
    "    plt.legend(handles=[line2],loc=7, bbox_to_anchor=(1.175, 0.05))\n",
    "    sns.despine()\n",
    "    plt.show() \n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# ss_rt_plots(df,'ALL SUBJS')\n",
    "# ss_rt_plots(df_hcs,'CONTROL SUBJS')\n",
    "# ss_rt_plots(df_pts,'PSYCHIATRIC SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# ss_rt_plots(df_hcs_avg,'AVG CONTROL SUBJS')\n",
    "# ss_rt_plots(df_pts_avg,'AVG PSYCHIATRIC SUBJS')\n",
    "# ss_rt_plots(df_avg,'AVG ALL SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     ss_rt_plots(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ss_roi_plots(df_type,sub_or_group):\n",
    "    for region in ['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']:\n",
    "        ##---------------------------------##\n",
    "        ## Plot SS and Behvaior\n",
    "        ##---------------------------------##  \n",
    "        plt.style.use('fivethirtyeight')\n",
    "        sns.set_style(\"darkgrid\",{\"axes.facecolor\":\".65\"})\n",
    "        sns.set_context('paper', font_scale=2.25)\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ## Plot reaction time and trial timeseries\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        fig = plt.figure(figsize=(20,7))\n",
    "        ax = plt.subplot2grid((4,4),(1,0),colspan=3,rowspan=3)\n",
    "        ss_title=\"%s | %s\" % (sub_or_group,region)\n",
    "        colors = np.where(df_type[\"cond\"], 'firebrick', 'navy')\n",
    "#         colors2 = np.where(df_type[\"cond\"], 'k', 'y')\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ## Use when plotting indivs or groups (not averages)\n",
    "#         markers = np.where(df_type[\"acc\"],'o','x').squeeze()\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ax.plot(df_type['trial'], df_type['rt'], color='w',linewidth=3, alpha=0.4,linestyle=\"dashed\")\n",
    "        ax.plot(df_type['trial'], df_type['%s' % region], color='k', linewidth=2, alpha=0.4)\n",
    "#         for x,y,c,m in zip(df_type['trial'], df_type['%s' % region], colors, markers):\n",
    "#             ax.scatter(x,y,s=40,marker=m,color=c)\n",
    "#         for x,y,c,m in zip(df_type['trial'], df_type['rt'], colors, markers):\n",
    "#             ax.scatter(x,y,s=40,marker=m,color=c)\n",
    "        for x,y,c in zip(df_type['trial'], df_type['rt'], colors):\n",
    "            ax.scatter(x,y,s=40,color=c,marker=\"^\")\n",
    "        for x,y,c in zip(df_type['trial'], df_type['%s' % region], colors):\n",
    "            ax.scatter(x,y,s=40,color=c,marker='o')\n",
    "        for color, label in zip(['navy', 'firebrick'], ['C','I']): \n",
    "            ax.scatter([],[], s=60, color=color, label=label)\n",
    "        # Configure matplotlib.patch.Patch properties\n",
    "        props = dict(facecolor='white',alpha=0.5)\n",
    "        ax.text(1.03, 0.6, r'$\\bigcirc \\bigtriangleup$ = Incongruent', transform=ax.transAxes, fontsize=18,\\\n",
    "            verticalalignment='top', bbox=props, color='firebrick')\n",
    "        ax.text(1.03, 0.4, r'$\\bigcirc \\bigtriangleup$ = Congruent', transform=ax.transAxes, fontsize=18,\\\n",
    "            verticalalignment='top', bbox=props, color='navy')\n",
    "        ##ax.text(1.03, 0.5, r'$\\bullet$ = $\\beta$', transform=ax.transAxes, fontsize=18,\\\n",
    "            ##verticalalignment='top', bbox=props, color='gold')\n",
    "        ax.set_xlim(0,190)\n",
    "        ax.set_xlabel('Trial Number', fontsize=18)\n",
    "        ax.set_ylabel(r'ROI $\\beta$ & Reaction Time', fontsize=18)\n",
    "        ax.set_title('MSIT | %s' % ss_title,loc='center')\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ## Plot state space\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        line1,=ax.plot(df_type[\"trial\"],df_type[\"conflict\"],linewidth=2,alpha=0.7,color='firebrick',label='Conflict')\n",
    "        line2,=ax.plot(df_type[\"trial\"],df_type[\"adapt\"],linewidth=2,alpha=0.7,color='navy',label='Adapt')\n",
    "        ## Conflict legend\n",
    "        first_legend = plt.legend(handles=[line1],loc=7, bbox_to_anchor=(1.175,0.95))\n",
    "        ax = plt.gca().add_artist(first_legend)\n",
    "        ## Adaptation legend\n",
    "        plt.legend(handles=[line2],loc=7, bbox_to_anchor=(1.175, 0.05))\n",
    "        sns.despine()\n",
    "        plt.show() \n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# ss_roi_plots(df,'ALL SUBJS')\n",
    "# ss_roi_plots(df_hcs,'CONTROL SUBJS')\n",
    "# ss_roi_plots(df_pts,'PSYCHIATRIC SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# ss_roi_plots(df_hcs_avg,'AVG CONTROL SUBJS')\n",
    "# ss_roi_plots(df_pts_avg,'AVG PSYCHIATRIC SUBJS')\n",
    "# ss_roi_plots(df_avg,'AVG ALL SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     ss_roi_plots(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Beta Series Method Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def timeseries_plots(df_type,sub_or_group):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sns.set_style(\"darkgrid\",{\"axes.facecolor\":\".85\"})\n",
    "    ##---------------------------------##\n",
    "    ##  Display fMRI time-series\n",
    "    ##---------------------------------##  \n",
    "    df_rois = df_type[['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']].copy()\n",
    "    df_rois.plot(subplots=True,figsize=(15, 6),fontsize=12,legend='right',linewidth=2)\n",
    "    plt.xlabel(\"%s\" % sub_or_group)\n",
    "    plt.show()\n",
    "    \n",
    "    df_vars = df_type[['conflict','adapt','rt']].copy()\n",
    "    df_vars.plot(subplots=True,figsize=(15, 6),fontsize=12,legend='right',linewidth=2)\n",
    "    plt.xlabel(\"%s\" % sub_or_group)\n",
    "    plt.show()\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# timeseries_plots(df,'ALL SUBJS')\n",
    "# timeseries_plots(df_hcs,'CONTROL SUBJS')\n",
    "# timeseries_plots(df_pts,'PSYCHIATRIC SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# timeseries_plots(df_hcs_avg,'AVG ALL CONTROL SUBJS')\n",
    "# timeseries_plots(df_pts_avg,'AVG ALL PSYCHIATRIC SUBJS')\n",
    "# timeseries_plots(df_avg,'AVG ALL SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     timeseries_plots(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of ITIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ITIs=[]\n",
    "subjects = ['hc001']\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "stim_blocks_path=os.path.join(raw_behav_dir,'stimuli_block.txt')\n",
    "stim_blocks=pd.read_csv(stim_blocks_path,names=['sequence'])\n",
    "\n",
    "rank_path=os.path.join(raw_behav_dir,'rank.txt')\n",
    "rank=pd.read_csv(rank_path,names=['rank'])\n",
    "\n",
    "for s in subjects:\n",
    "    bcsv=glob.glob(os.path.join(raw_behav_dir,'%s*' % s))\n",
    "    for file in bcsv:\n",
    "        b=pd.read_csv(file)\n",
    "        b['sequence'] = stim_blocks\n",
    "        b['rank'] = rank\n",
    "        for d,st in zip(b['Duration'],b['Stimuli']):\n",
    "            if st=='+':\n",
    "                ITIs.append(d)\n",
    "            else:\n",
    "                ITIs.append('0')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#         \n",
    "def plot_ITIs(ISI):           \n",
    "    sns.set()\n",
    "    plt.subplots(figsize=(5,10))\n",
    "    c=pd.DataFrame()\n",
    "    c['ITIs']=ISI\n",
    "    ax=sns.countplot(c['ITIs'],linewidth=5,facecolor=(0, 0, 0, 0),\\\n",
    "                  edgecolor=sns.color_palette(\"Set2\", 3),\\\n",
    "                  order = c['ITIs'].value_counts().index)\n",
    "    for p in ax.patches:\n",
    "            ax.annotate('   {:}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+2))\n",
    "    plt.show()\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# plot_ITIs(ITIs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subjects = ['hc001','hc002','hc003','hc004','hc005','hc006','hc009','hc010','hc011',\\\n",
    "             'hc012','hc014','hc015','hc017','hc018','hc019','hc021','hc023','hc028',\\\n",
    "             'hc031','hc032','hc033','hc034','hc036','hc038','hc042','pp001','pp002',\\\n",
    "             'pp003','pp004','pp005','pp006','pp007','pp008','pp010','pp011','pp012',\\\n",
    "             'pp013','pp015','pp016']\n",
    "# subjects = ['hc001']\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "stim_blocks_path=os.path.join(raw_behav_dir,'stimuli_block.txt')\n",
    "stim_blocks=pd.read_csv(stim_blocks_path,names=['sequence'])\n",
    "\n",
    "rank_path=os.path.join(raw_behav_dir,'rank.txt')\n",
    "rank=pd.read_csv(rank_path,names=['rank'])\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "for s in subjects:\n",
    "    bcsv=glob.glob(os.path.join(raw_behav_dir,'%s*' % s))\n",
    "    for file in bcsv:\n",
    "        rt=[]\n",
    "        dACC=[]\n",
    "        L_IFG=[]\n",
    "        R_IFG=[]\n",
    "        L_dlPFC=[]\n",
    "        R_dlPFC=[]\n",
    "        censor=[]\n",
    "        b=pd.read_csv(file)\n",
    "        b['sequence'] = stim_blocks\n",
    "        b['rank'] = rank \n",
    "        trials = b[ b['Stimuli'] != '+' ]\n",
    "        trials=trials[1:-2]\n",
    "        #---------------------------------##\n",
    "        file_1=os.path.join(LSS_dir,'%s.dACC_LSS_avg_file.1D' % s)\n",
    "        file_2=os.path.join(LSS_dir,'%s.L_IFG_LSS_avg_file.1D' % s)\n",
    "        file_3=os.path.join(LSS_dir,'%s.R_IFG_LSS_avg_file.1D' % s)\n",
    "        file_4=os.path.join(LSS_dir,'%s.L_dlPFC_LSS_avg_file.1D' % s)\n",
    "        file_5=os.path.join(LSS_dir,'%s.R_dlPFC_LSS_avg_file.1D' % s)\n",
    "        file_6=os.path.join(censor_dir,'msit.%s.msit_bsm.censor.1D' % s)\n",
    "        #---------------------------------##\n",
    "        ## Generate ROI variables\n",
    "        generate_roi_vars(file_1,dACC,\"dACC\")\n",
    "        generate_roi_vars(file_2,L_IFG,\"L_IFG\")\n",
    "        generate_roi_vars(file_3,R_IFG,\"R_IFG\")\n",
    "        generate_roi_vars(file_4,L_dlPFC,\"L_dlPFC\")\n",
    "        generate_roi_vars(file_5,R_dlPFC,\"R_dlPFC\")\n",
    "        censor_tps(file_6,censor,\"censor\")\n",
    "        #---------------------------------## \n",
    "        ## Interpolate missing ROI + RT data points\n",
    "        dACC = pd.Series(dACC).astype(float).interpolate()\n",
    "        R_IFG = pd.Series(R_IFG).astype(float).interpolate()\n",
    "        L_IFG = pd.Series(L_IFG).astype(float).interpolate()\n",
    "        L_dlPFC = pd.Series(L_dlPFC).astype(float).interpolate()\n",
    "        R_dlPFC = pd.Series(R_dlPFC).astype(float).interpolate()\n",
    "        #---------------------------------##\n",
    "        trials_df=pd.DataFrame({'dACC':dACC,'L_IFG':L_IFG,'R_IFG':R_IFG,\\\n",
    "                                'L_dlPFC':L_dlPFC,'R_dlPFC':R_dlPFC,\\\n",
    "                                'sequence':trials['sequence'],'rank':trials['rank'],\\\n",
    "                                'cond':trials['Condition']}) \n",
    "        # trials_df=trials_df.reset_index(drop=True)\n",
    "        \n",
    "        ROIs=['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']\n",
    "        for roi in ROIs:\n",
    "            sns.set()\n",
    "            ax=sns.lmplot(data=trials_df,x='rank',y='%s' % roi,hue='cond',markers=['o','x'])\n",
    "            plt.savefig(os.path.join(raw_behav_dir,'figs/%s.%s.conds.png' % (s,roi)))\n",
    "            ax.set(xlim=(0,18),xticks=range(1,18))\n",
    "            plt.title('%s' % s)\n",
    "            ax=sns.lmplot(data=trials_df,x='rank',y='%s' % roi)\n",
    "            ax.set(xlim=(0,18),xticks=range(1,18))\n",
    "            plt.title('%s' % s)\n",
    "            plt.savefig(os.path.join(raw_behav_dir,'figs/%s.%s.png' % (s,roi)))\n",
    "            plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
