{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as mp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.io import savemat, loadmat\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from scipy.stats import probplot, pearsonr\n",
    "from sklearn.preprocessing import scale,robust_scale\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import interp\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dACC_group=[]\n",
    "L_dlPFC_group=[]\n",
    "R_dlPFC_group=[]\n",
    "L_IFG_group=[]\n",
    "R_IFG_group=[]\n",
    "conflict_group=[]\n",
    "adapt_group=[]\n",
    "rt_group=[]\n",
    "\n",
    "dACC_group_hc=[]\n",
    "L_dlPFC_group_hc=[]\n",
    "R_dlPFC_group_hc=[]\n",
    "L_IFG_group_hc=[]\n",
    "R_IFG_group_hc=[]\n",
    "conflict_group_hc=[]\n",
    "adapt_group_hc=[]\n",
    "rt_group_hc=[]\n",
    "\n",
    "dACC_group_pts=[]\n",
    "L_dlPFC_group_pts=[]\n",
    "R_dlPFC_group_pts=[]\n",
    "L_IFG_group_pts=[]\n",
    "R_IFG_group_pts=[]\n",
    "conflict_group_pts=[]\n",
    "adapt_group_pts=[]\n",
    "rt_group_pts=[]\n",
    "\n",
    "regions=['dACC','L_dlPFC','R_dlPFC','L_IFG','R_IFG']\n",
    "variables=['rt','adapt','conflict']\n",
    "raw_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/msit_mri_behav'\n",
    "preproc_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/completed'\n",
    "LSS_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG'\n",
    "LSS_estim_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG_estim'\n",
    "censor_dir='/Users/emilyhahn/projects/msit_modeling/censor_data'\n",
    "\n",
    "df=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_I=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_C=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_I_C=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})\n",
    "\n",
    "df_I_epoch_first45=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})\n",
    "df_C_epoch_first45=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SUBJ_LIST = ['hc001','hc002','hc003','hc005','hc006','hc010','hc011','hc012','hc014',\\\n",
    "             'hc015','hc017','hc019','hc021','hc028','hc031','hc032','hc033','hc034',\\\n",
    "             'hc036','hc038','hc042','pp001','pp002','pp003','pp004','pp005','pp006',\\\n",
    "             'pp010','pp011','pp012','pp013','pp015','pp016']\n",
    "\n",
    "# SUBJ_LIST = ['hc001','pp001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions - Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers(rt_var,RT_arr,sub):\n",
    "    elements=[i for i in RT_arr]\n",
    "    mean = np.nanmean(elements)\n",
    "    sd = np.nanstd(elements)\n",
    "    sd_lower = mean - 5 * sd\n",
    "    sd_upper = mean + 5 * sd\n",
    "    for x in elements:\n",
    "        if (sd_lower <= x <= sd_upper):\n",
    "            rt_var.append(x)\n",
    "        else:\n",
    "            rt_var.append('NaN')\n",
    "            print '%s\\n%.2f RT value excluded: not in range SD min (%.2f) to SD max (%.2f)' % (sub,x,sd_lower,sd_upper)\n",
    "    return\n",
    "\n",
    "def generate_roi_vars(roi_file,region,var,sub):\n",
    "    elements=[]\n",
    "    with open(roi_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            line=float(line)\n",
    "            elements.append(line)\n",
    "    mean = np.nanmean(elements)\n",
    "    sd = np.nanstd(elements)\n",
    "    sd_lower = mean - 5 * sd\n",
    "    sd_upper = mean + 5 * sd\n",
    "    for x in elements:\n",
    "        if (sd_lower <= x <= sd_upper):\n",
    "            region.append(x)\n",
    "        else:\n",
    "            region.append('NaN')\n",
    "            print '%s\\n%.2f %s beta excluded: not in range SD min (%.2f) to SD max (%.2f)' % (sub,x,var,sd_lower,sd_upper) \n",
    "    return\n",
    "\n",
    "def censor_tps(censor_file,censor_var,var):\n",
    "    with open(censor_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            censor_var.append(line)\n",
    "    return\n",
    "\n",
    "def build_plots(ROI,variable,df_type,group,cond,sub):\n",
    "    slope, intercept, r_value, p_value, std_err = \\\n",
    "            stats.linregress(df_type['%s' % variable],df_type['%s' % ROI])\n",
    "#     if (p_value <= 1):\n",
    "    sns.set()\n",
    "    g=sns.JointGrid(x='%s' % variable, y='%s' % ROI, data=df_type)\n",
    "    g=g.plot(sns.regplot,sns.distplot)\n",
    "    lin_reg_r = lambda a, b: stats.linregress(df_type['%s' % variable], df_type['%s' % ROI])[2:4]\n",
    "    g = g.annotate(lin_reg_r, template=\"{stat}: {val:.2f} $p=$ {p:.2f}\",stat=\"$r=$\",loc=\"upper left\")                                                                        \n",
    "    plt.subplots_adjust(top=0.93)\n",
    "#     g.fig.suptitle(\"%s | %s\" % (group,cond))\n",
    "    g.fig.suptitle(\"%s | %s | %s\" % (group,cond,sub))\n",
    "#     g.savefig('/Users/emilyhahn/projects/msit_modeling/figures/%s_%s_%s_%s.png' % (ROI,variable,group,cond))\n",
    "    plt.show()\n",
    "#     else:\n",
    "#         print \"**** %s %s %s not significant ****\" % (SUBJ,ROI,cond)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Indiv and Group Data - SS output, ROI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hc005\n",
      "8.68 dACC beta excluded: not in range SD min (-4.03) to SD max (4.25)\n",
      "hc006\n",
      "nan RT value excluded: not in range SD min (-0.33) to SD max (2.45)\n",
      "hc019\n",
      "nan RT value excluded: not in range SD min (-0.02) to SD max (2.26)\n",
      "hc019\n",
      "nan RT value excluded: not in range SD min (-0.02) to SD max (2.26)\n",
      "hc019\n",
      "nan RT value excluded: not in range SD min (-0.02) to SD max (2.26)\n",
      "hc019\n",
      "nan RT value excluded: not in range SD min (-0.02) to SD max (2.26)\n",
      "hc021\n",
      "nan RT value excluded: not in range SD min (0.04) to SD max (2.09)\n",
      "hc028\n",
      "nan RT value excluded: not in range SD min (-0.45) to SD max (1.98)\n",
      "hc028\n",
      "nan RT value excluded: not in range SD min (-0.45) to SD max (1.98)\n",
      "hc031\n",
      "nan RT value excluded: not in range SD min (-0.17) to SD max (1.79)\n",
      "hc031\n",
      "nan RT value excluded: not in range SD min (-0.17) to SD max (1.79)\n",
      "hc031\n",
      "nan RT value excluded: not in range SD min (-0.17) to SD max (1.79)\n",
      "hc031\n",
      "nan RT value excluded: not in range SD min (-0.17) to SD max (1.79)\n",
      "hc031\n",
      "nan RT value excluded: not in range SD min (-0.17) to SD max (1.79)\n",
      "hc031\n",
      "nan RT value excluded: not in range SD min (-0.17) to SD max (1.79)\n",
      "hc031\n",
      "nan RT value excluded: not in range SD min (-0.17) to SD max (1.79)\n",
      "hc031\n",
      "nan RT value excluded: not in range SD min (-0.17) to SD max (1.79)\n",
      "hc036\n",
      "nan RT value excluded: not in range SD min (-0.29) to SD max (1.79)\n",
      "hc038\n",
      "8.33 L_dlPFC beta excluded: not in range SD min (-7.00) to SD max (7.27)\n",
      "hc042\n",
      "0.46 R_dlPFC beta excluded: not in range SD min (-0.40) to SD max (0.45)\n",
      "hc042\n",
      "0.48 R_dlPFC beta excluded: not in range SD min (-0.40) to SD max (0.45)\n",
      "pp004\n",
      "nan RT value excluded: not in range SD min (-0.26) to SD max (2.59)\n",
      "pp004\n",
      "nan RT value excluded: not in range SD min (-0.26) to SD max (2.59)\n",
      "pp004\n",
      "nan RT value excluded: not in range SD min (-0.26) to SD max (2.59)\n",
      "pp004\n",
      "nan RT value excluded: not in range SD min (-0.26) to SD max (2.59)\n",
      "pp004\n",
      "nan RT value excluded: not in range SD min (-0.26) to SD max (2.59)\n",
      "pp004\n",
      "nan RT value excluded: not in range SD min (-0.26) to SD max (2.59)\n",
      "pp004\n",
      "nan RT value excluded: not in range SD min (-0.26) to SD max (2.59)\n",
      "pp004\n",
      "nan RT value excluded: not in range SD min (-0.26) to SD max (2.59)\n",
      "pp004\n",
      "1.51 R_IFG beta excluded: not in range SD min (-1.10) to SD max (1.25)\n",
      "pp006\n",
      "nan RT value excluded: not in range SD min (-0.28) to SD max (2.48)\n",
      "pp006\n",
      "nan RT value excluded: not in range SD min (-0.28) to SD max (2.48)\n",
      "pp006\n",
      "nan RT value excluded: not in range SD min (-0.28) to SD max (2.48)\n",
      "pp006\n",
      "3.74 R_IFG beta excluded: not in range SD min (-2.91) to SD max (3.04)\n",
      "pp006\n",
      "2.41 L_dlPFC beta excluded: not in range SD min (-1.76) to SD max (2.02)\n",
      "pp012\n",
      "nan RT value excluded: not in range SD min (-0.33) to SD max (2.29)\n",
      "pp012\n",
      "nan RT value excluded: not in range SD min (-0.33) to SD max (2.29)\n",
      "pp013\n",
      "0.09 L_dlPFC beta excluded: not in range SD min (-0.08) to SD max (0.08)\n",
      "pp013\n",
      "0.08 L_dlPFC beta excluded: not in range SD min (-0.08) to SD max (0.08)\n",
      "pp015\n",
      "nan RT value excluded: not in range SD min (-0.14) to SD max (1.79)\n"
     ]
    }
   ],
   "source": [
    "for SUBJ in SUBJ_LIST:\n",
    "    bcsv=glob.glob(os.path.join(raw_behav_dir,'%s*' % SUBJ))\n",
    "    for file in bcsv:\n",
    "        rt=[]\n",
    "        RT=[]\n",
    "        RT_orig=[]\n",
    "        conflict=[]\n",
    "        adapt=[]\n",
    "        dACC=[]\n",
    "        L_IFG=[]\n",
    "        R_IFG=[]\n",
    "        L_dlPFC=[]\n",
    "        R_dlPFC=[]\n",
    "        cond=[]\n",
    "        trial=[]\n",
    "        acc=[]\n",
    "        censor=[]   \n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        stim_blocks_path=os.path.join(raw_behav_dir,'stimuli_block.txt')\n",
    "        stim_blocks=pd.read_csv(stim_blocks_path,names=['sequence'])\n",
    "\n",
    "        rank_path=os.path.join(raw_behav_dir,'rank.txt')\n",
    "        rank=pd.read_csv(rank_path,names=['rank'])\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        b=pd.read_csv(file)\n",
    "        b['sequence'] = stim_blocks\n",
    "        b['rank'] = rank \n",
    "        trials = b[ b['Stimuli'] != '+' ]\n",
    "        trials=trials[1:-2]\n",
    "        trials_df=pd.DataFrame({'sequence':trials['sequence'],'rank':trials['rank']})\n",
    "        trials_df=trials_df.reset_index(drop=True)\n",
    "        #---------------------------------##\n",
    "        ## Configure SS variables\n",
    "        #---------------------------------##\n",
    "        mat = loadmat(os.path.join(preproc_behav_dir,'%s_msit_ss_iter250.mat') % SUBJ)\n",
    "        #---------------------------------##\n",
    "        ss_outputs_xsmt = np.expand_dims(np.array([np.concatenate(arr) \\\n",
    "                                    for arr in mat['XSmt']]).squeeze(),1)\n",
    "        ss_xsmt = ss_outputs_xsmt.squeeze()\n",
    "        RT.extend([float(i) for i in np.array(mat['RT'].squeeze())])\n",
    "        remove_outliers(rt,RT,SUBJ)\n",
    "        #---------------------------------##\n",
    "        conflict.extend([float(i[0]) for i in ss_xsmt])\n",
    "        adapt.extend([float(i[1]) for i in ss_xsmt])\n",
    "        acc.extend([float(i) for i in np.array(mat['Accuracy'].squeeze())])\n",
    "        trial.extend([float(i) for i in np.array(mat['Trial'].squeeze())])\n",
    "        cond.extend([float(i) for i in np.array(mat['Interference'].squeeze())])\n",
    "        #---------------------------------##\n",
    "        ## Configure ROI variables\n",
    "        #---------------------------------##\n",
    "        ## Load indiv ROI vars\n",
    "        file_1=os.path.join(LSS_dir,'%s.dACC_LSS_avg_file.1D' % SUBJ)\n",
    "        file_2=os.path.join(LSS_dir,'%s.L_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "        file_3=os.path.join(LSS_dir,'%s.R_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "        file_4=os.path.join(LSS_dir,'%s.L_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "        file_5=os.path.join(LSS_dir,'%s.R_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "        file_6=os.path.join(censor_dir,'msit.%s.msit_bsm.censor.1D' % SUBJ)\n",
    "        #---------------------------------##\n",
    "        ## Generate ROI variables\n",
    "        generate_roi_vars(file_1,dACC,\"dACC\",SUBJ)\n",
    "        generate_roi_vars(file_2,L_IFG,\"L_IFG\",SUBJ)\n",
    "        generate_roi_vars(file_3,R_IFG,\"R_IFG\",SUBJ)\n",
    "        generate_roi_vars(file_4,L_dlPFC,\"L_dlPFC\",SUBJ)\n",
    "        generate_roi_vars(file_5,R_dlPFC,\"R_dlPFC\",SUBJ)\n",
    "        #---------------------------------##\n",
    "        censor_tps(file_6,censor,\"censor\")\n",
    "        #---------------------------------##\n",
    "        ## insert RT outliers scrubbing function here\n",
    "        #---------------------------------##\n",
    "        ## Determine group\n",
    "        s=[]\n",
    "        if 'hc' in SUBJ:\n",
    "            s.append(0)\n",
    "        elif 'pp' in SUBJ:\n",
    "            s.append(1)\n",
    "        GROUP_ARR=np.array([\"%s\" % s] * len(trial))\n",
    "        group=[float(i.strip('[]')) for i in GROUP_ARR]\n",
    "        SUBJ_ARR=np.array([\"%s\" % SUBJ] * len(trial))\n",
    "        #---------------------------------## \n",
    "        ## Scale + interpolate missing ROI + RT data points\n",
    "        ## Configure this section to statistically appropriate scaling\n",
    "\n",
    "        dACC = pd.Series(dACC).astype(float).interpolate()\n",
    "        R_IFG = pd.Series(R_IFG).astype(float).interpolate()\n",
    "        L_IFG = pd.Series(L_IFG).astype(float).interpolate()\n",
    "        L_dlPFC = pd.Series(L_dlPFC).astype(float).interpolate()\n",
    "        R_dlPFC = pd.Series(R_dlPFC).astype(float).interpolate()\n",
    "\n",
    "        rt = preprocessing.scale(pd.Series(rt).astype(float).interpolate())\n",
    "        #---------------------------------## \n",
    "        dACC_group.append(dACC)\n",
    "        L_dlPFC_group.append(L_dlPFC)\n",
    "        R_dlPFC_group.append(R_dlPFC)\n",
    "        L_IFG_group.append(L_IFG)\n",
    "        R_IFG_group.append(R_IFG)\n",
    "        conflict_group.append(conflict)\n",
    "        adapt_group.append(adapt)\n",
    "        rt_group.append(rt)\n",
    "        #---------------------------------##\n",
    "        if 'pp' in SUBJ_ARR[0]:\n",
    "            dACC_group_pts.append(dACC)\n",
    "            L_dlPFC_group_pts.append(L_dlPFC)\n",
    "            R_dlPFC_group_pts.append(R_dlPFC)\n",
    "            L_IFG_group_pts.append(L_IFG)\n",
    "            R_IFG_group_pts.append(R_IFG)\n",
    "            conflict_group_pts.append(conflict)\n",
    "            adapt_group_pts.append(adapt)\n",
    "            rt_group_pts.append(rt)\n",
    "        elif 'hc' in SUBJ_ARR[0]:\n",
    "            dACC_group_hc.append(dACC)\n",
    "            L_dlPFC_group_hc.append(L_dlPFC)\n",
    "            R_dlPFC_group_hc.append(R_dlPFC)\n",
    "            L_IFG_group_hc.append(L_IFG)\n",
    "            R_IFG_group_hc.append(R_IFG)\n",
    "            conflict_group_hc.append(conflict)\n",
    "            adapt_group_hc.append(adapt)  \n",
    "            rt_group_hc.append(rt)\n",
    "        else:\n",
    "            \"REVIEW SUBJ ID: %s\" % SUBJ\n",
    "        ##---------------------------------##\n",
    "        ## Append subj data to master DF\n",
    "        ##---------------------------------##\n",
    "        df1=pd.DataFrame({\"group\":group,\"subject\":SUBJ_ARR,'rt':rt,'dACC':dACC,'L_IFG':L_IFG,\\\n",
    "                          'R_IFG':R_IFG,'L_dlPFC':L_dlPFC,'R_dlPFC':R_dlPFC,'trial':trial,\\\n",
    "                          'cond':cond,'acc':acc,'conflict':conflict,'adapt':adapt})\n",
    "        ##---------------------------------##\n",
    "        df=df.append(df1)\n",
    "        df1_C=df1[df1.cond == 0]\n",
    "        df1_I=df1[df1.cond == 1]\n",
    "        ##---------------------------------##\n",
    "    #     conditions = ['Incongruent','Congruent']\n",
    "    #     rois = ['dACC']\n",
    "\n",
    "    #     for c in conditions:\n",
    "    #         for region in rois:\n",
    "    #             for variable in variables:\n",
    "    #                 if 'pp' in SUBJ and c=='Incongruent':\n",
    "    #                     build_plots('%s' % region,'%s' % variable,df1_I,'PSYCH','%s' % c,SUBJ)\n",
    "    #                 elif 'pp' in SUBJ and c=='Congruent':\n",
    "    #                     build_plots('%s' % region,'%s' % variable,df1_C,'PSYCH','%s' % c,SUBJ)\n",
    "    #                 elif 'hc' in SUBJ and c=='Incongruent':\n",
    "    #                     build_plots('%s' % region,'%s' % variable,df1_I,'CTRL','%s' % c,SUBJ)\n",
    "    #                 elif 'hc' in SUBJ and c=='Congruent':\n",
    "    #                     build_plots('%s' % region,'%s' % variable,df1_C,'CTRL','%s' % c,SUBJ)\n",
    "    #                 else:\n",
    "    #                     print '%s %s %s %s' % (g,c,region,variable)\n",
    "        ##---------------------------------##\n",
    "        df1_C_epoch_first45=df1_C[:][0:50].reset_index(drop=True).mean(axis=0,numeric_only=True) \n",
    "        df1_I_epoch_first45=df1_I[:][0:50].reset_index(drop=True).mean(axis=0,numeric_only=True)\n",
    "        ##---------------------------------##\n",
    "        df1_C=df1_C.mean(axis=0,numeric_only=True)\n",
    "        df1_I=df1_I.mean(axis=0,numeric_only=True)\n",
    "        ##---------------------------------##\n",
    "        ##---------------------------------##\n",
    "        S=group[0]\n",
    "        df1_C['subject']=SUBJ\n",
    "        df1_C['group']=S\n",
    "        df1_I['subject']=SUBJ\n",
    "        df1_I['group']=S\n",
    "        df1_I_epoch_first45['subject']=SUBJ\n",
    "        df1_I_epoch_first45['group']=S\n",
    "        df1_C_epoch_first45['subject']=SUBJ\n",
    "        df1_C_epoch_first45['group']=S\n",
    "        ##---------------------------------##\n",
    "        df_I=df_I.append(df1_I,ignore_index=True)\n",
    "        df_C=df_C.append(df1_C,ignore_index=True)\n",
    "\n",
    "        df_I_epoch_first45=df_I_epoch_first45.append(df1_I_epoch_first45,ignore_index=True)\n",
    "        df_C_epoch_first45=df_C_epoch_first45.append(df1_C_epoch_first45,ignore_index=True)\n",
    "        ##---------------------------------##\n",
    "        df1_I_C=pd.DataFrame(data={\"group\":S,\"subject\":SUBJ,'rt':df1_I['rt']-df1_C['rt']},index=[1])\n",
    "        df1_I_C={\"group\":S,\"subject\":SUBJ,\\\n",
    "                 'rt':df1_I['rt']-df1_C['rt'],\\\n",
    "                 'dACC':df1_I['dACC']-df1_C['dACC'],\\\n",
    "                 'L_IFG': df1_I['L_IFG']-df1_C['L_IFG'],\\\n",
    "                 'R_IFG': df1_I['R_IFG']-df1_C['R_IFG'],\\\n",
    "                 'L_dlPFC': df1_I['L_dlPFC']-df1_C['L_dlPFC'],\\\n",
    "                 'R_dlPFC': df1_I['R_dlPFC']-df1_C['R_dlPFC'],\\\n",
    "                 'acc': df1_I['acc']-df1_C['acc'],\\\n",
    "                 'conflict': df1_I['conflict']-df1_C['conflict'],\\\n",
    "                 'adapt': df1_I['adapt']-df1_C['adapt'] }\n",
    "        df_I_C=df_I_C.append(df1_I_C,ignore_index=True)\n",
    "##---------------------------------##\n",
    "## Parse DataFrames\n",
    "##---------------------------------##\n",
    "df_hcs=df.where(df['group']==0).dropna()\n",
    "df_pts=df.where(df['group']==1).dropna()\n",
    "df_hcs_I=df_I.where(df_I['group']==0).dropna().reset_index(drop=True)\n",
    "df_pts_I=df_I.where(df_I['group']==1).dropna().reset_index(drop=True)\n",
    "df_hcs_C=df_C.where(df_C['group']==0).dropna().reset_index(drop=True)\n",
    "df_pts_C=df_C.where(df_C['group']==1).dropna().reset_index(drop=True)\n",
    "df_hcs_I_epoch_first45=df_I_epoch_first45.where(df_I_epoch_first45['group']==0).dropna().reset_index(drop=True)\n",
    "df_hcs_C_epoch_first45=df_C_epoch_first45.where(df_C_epoch_first45['group']==0).dropna().reset_index(drop=True)\n",
    "df_pts_I_epoch_first45=df_I_epoch_first45.where(df_I_epoch_first45['group']==1).dropna().reset_index(drop=True)\n",
    "df_pts_C_epoch_first45=df_C_epoch_first45.where(df_C_epoch_first45['group']==1).dropna().reset_index(drop=True)\n",
    "##---------------------------------##\n",
    "## Compute time-series means for ALL subjs\n",
    "##---------------------------------##\n",
    "dACC_group_avg=np.mean(dACC_group, axis=0, dtype=np.float64)\n",
    "L_IFG_group_avg=np.mean(L_IFG_group, axis=0, dtype=np.float64)\n",
    "R_IFG_group_avg=np.mean(R_IFG_group, axis=0, dtype=np.float64)\n",
    "L_dlPFC_group_avg=np.mean(L_dlPFC_group, axis=0, dtype=np.float64)\n",
    "R_dlPFC_group_avg=np.mean(R_dlPFC_group, axis=0, dtype=np.float64)\n",
    "conflict_group_avg=np.mean(conflict_group, axis=0, dtype=np.float64)\n",
    "adapt_group_avg=np.mean(adapt_group, axis=0, dtype=np.float64)\n",
    "rt_group_avg=np.mean(rt_group, axis=0, dtype=np.float64)\n",
    "##---------------------------------##\n",
    "## Compute time-series means for HC subjs\n",
    "##---------------------------------##\n",
    "dACC_group_hc_avg=np.mean(dACC_group_hc, axis=0, dtype=np.float64)\n",
    "L_IFG_group_hc_avg=np.mean(L_IFG_group_hc, axis=0, dtype=np.float64)\n",
    "R_IFG_group_hc_avg=np.mean(R_IFG_group_hc, axis=0, dtype=np.float64)\n",
    "L_dlPFC_group_hc_avg=np.mean(L_dlPFC_group_hc, axis=0, dtype=np.float64)\n",
    "R_dlPFC_group_hc_avg=np.mean(R_dlPFC_group_hc, axis=0, dtype=np.float64)\n",
    "conflict_group_hc_avg=np.mean(conflict_group_hc, axis=0, dtype=np.float64)\n",
    "adapt_group_hc_avg=np.mean(adapt_group_hc, axis=0, dtype=np.float64)\n",
    "rt_group_hc_avg=np.mean(rt_group_hc, axis=0, dtype=np.float64)\n",
    "##---------------------------------##\n",
    "## Compute time-series means for PTS subjs\n",
    "##---------------------------------##\n",
    "dACC_group_pts_avg=np.mean(dACC_group_pts, axis=0, dtype=np.float64)\n",
    "L_IFG_group_pts_avg=np.mean(L_IFG_group_pts, axis=0, dtype=np.float64)\n",
    "R_IFG_group_pts_avg=np.mean(R_IFG_group_pts, axis=0, dtype=np.float64)\n",
    "L_dlPFC_group_pts_avg=np.mean(L_dlPFC_group_pts, axis=0, dtype=np.float64)\n",
    "R_dlPFC_group_pts_avg=np.mean(R_dlPFC_group_pts, axis=0, dtype=np.float64)\n",
    "conflict_group_pts_avg=np.mean(conflict_group_pts, axis=0, dtype=np.float64)\n",
    "adapt_group_pts_avg=np.mean(adapt_group_pts, axis=0, dtype=np.float64)\n",
    "rt_group_pts_avg=np.mean(rt_group_pts, axis=0, dtype=np.float64)\n",
    "##---------------------------------##\n",
    "## Parse time-series Data Frames\n",
    "##---------------------------------##\n",
    "df_avg=pd.DataFrame({'rt':rt_group_avg,'dACC':dACC_group_avg,'L_IFG':L_IFG_group_avg,\\\n",
    "                     'R_IFG':R_IFG_group_avg,'L_dlPFC':L_dlPFC_group_avg,\\\n",
    "                     'R_dlPFC':R_dlPFC_group_avg,'trial':trial,'cond':cond,\\\n",
    "                     'conflict':conflict_group_avg,'adapt':adapt_group_avg})\n",
    "df_hcs_avg=pd.DataFrame({'rt':rt_group_hc_avg,'dACC':dACC_group_hc_avg,'L_IFG':L_IFG_group_hc_avg,\\\n",
    "                     'R_IFG':R_IFG_group_hc_avg,'L_dlPFC':L_dlPFC_group_hc_avg,\\\n",
    "                     'R_dlPFC':R_dlPFC_group_hc_avg,'trial':trial,'cond':cond,\\\n",
    "                     'conflict':conflict_group_hc_avg,'adapt':adapt_group_hc_avg})\n",
    "df_pts_avg=pd.DataFrame({'rt':rt_group_pts_avg,'dACC':dACC_group_pts_avg,'L_IFG':L_IFG_group_pts_avg,\\\n",
    "                     'R_IFG':R_IFG_group_pts_avg,'L_dlPFC':L_dlPFC_group_pts_avg,\\\n",
    "                     'R_dlPFC':R_dlPFC_group_pts_avg,'trial':trial,'cond':cond,\\\n",
    "                     'conflict':conflict_group_pts_avg,'adapt':adapt_group_pts_avg})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##---------------------------------##\n",
    "# Documentation on MLE plotting:\n",
    "# \"https://www.statsmodels.org/devel/_modules/statsmodels/regression/mixed_linear_model.html\"\n",
    "##---------------------------------##\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "def mixed_LM_rank(df_type,sub_or_group):\n",
    "    for beta in ['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']:\n",
    "        md = smf.mixedlm(\"%s ~ rank * cond\" % beta,data=df_type,groups='subject')\n",
    "        mdf = md.fit()\n",
    "        print(mdf.summary())\n",
    "        likev = mdf.profile_re(0, 're', dist_low=.001, dist_high=.01)\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.plot(likev[:,0], 2*likev[:,1])\n",
    "        plt.xlabel(\"Variance of random slope\", size=12)\n",
    "        plt.ylabel(\"-2 times profile log likelihood\", size=12)\n",
    "        plt.title(\"%s\" % beta)\n",
    "        plt.show()\n",
    "    return\n",
    "# mixed_LM_rank(df,'ALL SUBJS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize SS variables, RT, Cond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ss_rt_plots(df_type,sub_or_group):\n",
    "    ##---------------------------------##\n",
    "    ## Plot SS and Behvaior\n",
    "    ##---------------------------------##  \n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sns.set_style(\"darkgrid\",{\"axes.facecolor\":\".85\"})\n",
    "    sns.set_context('paper', font_scale=2.25)\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ## Plot reaction time and trial timeseries\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    fig = plt.figure(figsize=(20,7))\n",
    "    ax = plt.subplot2grid((4,4),(1,0),colspan=3,rowspan=3)\n",
    "    ss_title=\"MSIT | %s\" % sub_or_group\n",
    "    colors = np.where(df_type[\"cond\"], 'firebrick', 'navy')\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ## Use when plotting indivs or groups (not averages)\n",
    "#     markers = np.where(df_type[\"acc\"],'o','x').squeeze()\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ax.plot(df_type[\"trial\"], df_type[\"rt\"], color='k', linewidth=2, alpha=0.4)\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    for x,y,c in zip(df_type['trial'], df_type[\"rt\"], colors): \n",
    "        ax.scatter(x,y,s=40,color=c)\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ## Use when plotting indivs or groups (not averages)\n",
    "#     for x,y,c,m in zip(df_type['trial'], df_type[\"rt\"], colors, markers): \n",
    "#         ax.scatter(x,y,s=40,marker=m,color=c)\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    for color, label in zip(['navy', 'firebrick'], ['C','I']): \n",
    "        ax.scatter([],[], s=60, color=color, label=label)\n",
    "    # Configure matplotlib.patch.Patch properties\n",
    "    props = dict(facecolor='white',alpha=0.5)\n",
    "    ax.text(1.03, 0.6, r'$\\bigcirc$ = Incongruent', transform=ax.transAxes, fontsize=18,\\\n",
    "        verticalalignment='top', bbox=props, color='firebrick')\n",
    "    ax.text(1.03, 0.4, r'$\\bigcirc$ = Congruent', transform=ax.transAxes, fontsize=18,\\\n",
    "        verticalalignment='top', bbox=props, color='navy')\n",
    "    ax.set_xlim(0,190)\n",
    "    ax.set_xlabel('Trial Number', fontsize=18)\n",
    "    ax.set_ylabel('Reaction Time', fontsize=18)\n",
    "    ax.set_title('%s' % ss_title,loc='center')\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    ## Plot state space\n",
    "    ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "    line1,=ax.plot(df_type[\"trial\"],df_type[\"conflict\"],linewidth=2,alpha=0.7,color='firebrick',label='Conflict')\n",
    "    line2,=ax.plot(df_type[\"trial\"],df_type[\"adapt\"],linewidth=2,alpha=0.7,color='navy',label='Adapt')\n",
    "#     Conflict legend\n",
    "    first_legend = plt.legend(handles=[line1],loc=7, bbox_to_anchor=(1.175,0.95))\n",
    "    ax = plt.gca().add_artist(first_legend)\n",
    "#     Adaptation legend\n",
    "    plt.legend(handles=[line2],loc=7, bbox_to_anchor=(1.175, 0.05))\n",
    "    sns.despine()\n",
    "    plt.show() \n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     ss_rt_plots(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ss_roi_plots(df_type,sub_or_group):\n",
    "    for region in ['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']:\n",
    "        ##---------------------------------##\n",
    "        ## Plot SS and Behvaior\n",
    "        ##---------------------------------##  \n",
    "        plt.style.use('fivethirtyeight')\n",
    "        sns.set_style(\"darkgrid\",{\"axes.facecolor\":\".65\"})\n",
    "        sns.set_context('paper', font_scale=2.25)\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ## Plot reaction time and trial timeseries\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        fig = plt.figure(figsize=(20,7))\n",
    "        ax = plt.subplot2grid((4,4),(1,0),colspan=3,rowspan=3)\n",
    "        ss_title=\"%s | %s\" % (sub_or_group,region)\n",
    "        colors = np.where(df_type[\"cond\"], 'firebrick', 'navy')\n",
    "#         colors2 = np.where(df_type[\"cond\"], 'k', 'y')\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ## Use when plotting indivs or groups (not averages)\n",
    "#         markers = np.where(df_type[\"acc\"],'o','x').squeeze()\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ax.plot(df_type['trial'], df_type['rt'], color='w',linewidth=3, alpha=0.4,linestyle=\"dashed\")\n",
    "        ax.plot(df_type['trial'], df_type['%s' % region], color='k', linewidth=2, alpha=0.4)\n",
    "#         for x,y,c,m in zip(df_type['trial'], df_type['%s' % region], colors, markers):\n",
    "#             ax.scatter(x,y,s=40,marker=m,color=c)\n",
    "#         for x,y,c,m in zip(df_type['trial'], df_type['rt'], colors, markers):\n",
    "#             ax.scatter(x,y,s=40,marker=m,color=c)\n",
    "        for x,y,c in zip(df_type['trial'], df_type['rt'], colors):\n",
    "            ax.scatter(x,y,s=40,color=c,marker=\"^\")\n",
    "        for x,y,c in zip(df_type['trial'], df_type['%s' % region], colors):\n",
    "            ax.scatter(x,y,s=40,color=c,marker='o')\n",
    "        for color, label in zip(['navy', 'firebrick'], ['C','I']): \n",
    "            ax.scatter([],[], s=60, color=color, label=label)\n",
    "        # Configure matplotlib.patch.Patch properties\n",
    "        props = dict(facecolor='white',alpha=0.5)\n",
    "        ax.text(1.03, 0.6, r'$\\bigcirc \\bigtriangleup$ = Incongruent', transform=ax.transAxes, fontsize=18,\\\n",
    "            verticalalignment='top', bbox=props, color='firebrick')\n",
    "        ax.text(1.03, 0.4, r'$\\bigcirc \\bigtriangleup$ = Congruent', transform=ax.transAxes, fontsize=18,\\\n",
    "            verticalalignment='top', bbox=props, color='navy')\n",
    "        ##ax.text(1.03, 0.5, r'$\\bullet$ = $\\beta$', transform=ax.transAxes, fontsize=18,\\\n",
    "            ##verticalalignment='top', bbox=props, color='gold')\n",
    "        ax.set_xlim(0,190)\n",
    "        ax.set_xlabel('Trial Number', fontsize=18)\n",
    "        ax.set_ylabel(r'ROI $\\beta$ & Reaction Time', fontsize=18)\n",
    "        ax.set_title('MSIT | %s' % ss_title,loc='center')\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        ## Plot state space\n",
    "        ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "        line1,=ax.plot(df_type[\"trial\"],df_type[\"conflict\"],linewidth=2,alpha=0.7,color='firebrick',label='Conflict')\n",
    "        line2,=ax.plot(df_type[\"trial\"],df_type[\"adapt\"],linewidth=2,alpha=0.7,color='navy',label='Adapt')\n",
    "        ## Conflict legend\n",
    "        first_legend = plt.legend(handles=[line1],loc=7, bbox_to_anchor=(1.175,0.95))\n",
    "        ax = plt.gca().add_artist(first_legend)\n",
    "        ## Adaptation legend\n",
    "        plt.legend(handles=[line2],loc=7, bbox_to_anchor=(1.175, 0.05))\n",
    "        sns.despine()\n",
    "        plt.show() \n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     ss_roi_plots(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Beta Series Method Timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def timeseries_plots(df_type,sub_or_group):\n",
    "    plt.style.use('fivethirtyeight')\n",
    "    sns.set_style(\"darkgrid\",{\"axes.facecolor\":\".85\"})\n",
    "    ##---------------------------------##\n",
    "    ##  Display fMRI time-series\n",
    "    ##---------------------------------##  \n",
    "    df_rois = df_type[['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']].copy()\n",
    "    df_rois.plot(subplots=True,figsize=(15, 6),fontsize=12,legend='right',linewidth=2)\n",
    "    plt.xlabel(\"%s\" % sub_or_group)\n",
    "    plt.show()\n",
    "    \n",
    "    df_vars = df_type[['conflict','adapt','rt']].copy()\n",
    "    df_vars.plot(subplots=True,figsize=(15, 6),fontsize=12,legend='right',linewidth=2)\n",
    "    plt.xlabel(\"%s\" % sub_or_group)\n",
    "    plt.show()\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# timeseries_plots(df_hcs_avg,'AVG ALL CONTROL SUBJS')\n",
    "# timeseries_plots(df_pts_avg,'AVG ALL PSYCHIATRIC SUBJS')\n",
    "# timeseries_plots(df_avg,'AVG ALL SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     timeseries_plots(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of ITIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ITIs=[]\n",
    "subjects = ['hc001']\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "stim_blocks_path=os.path.join(raw_behav_dir,'stimuli_block.txt')\n",
    "stim_blocks=pd.read_csv(stim_blocks_path,names=['sequence'])\n",
    "\n",
    "rank_path=os.path.join(raw_behav_dir,'rank.txt')\n",
    "rank=pd.read_csv(rank_path,names=['rank'])\n",
    "\n",
    "for s in subjects:\n",
    "    bcsv=glob.glob(os.path.join(raw_behav_dir,'%s*' % s))\n",
    "    for file in bcsv:\n",
    "        b=pd.read_csv(file)\n",
    "        b['sequence'] = stim_blocks\n",
    "        b['rank'] = rank\n",
    "        for d,st in zip(b['Duration'],b['Stimuli']):\n",
    "            if st=='+':\n",
    "                ITIs.append(d)\n",
    "            else:\n",
    "                ITIs.append('0')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#         \n",
    "def plot_ITIs(ISI):           \n",
    "    sns.set()\n",
    "    plt.subplots(figsize=(5,10))\n",
    "    c=pd.DataFrame()\n",
    "    c['ITIs']=ISI\n",
    "    ax=sns.countplot(c['ITIs'],linewidth=5,facecolor=(0, 0, 0, 0),\\\n",
    "                  edgecolor=sns.color_palette(\"Set2\", 3),\\\n",
    "                  order = c['ITIs'].value_counts().index)\n",
    "    for p in ax.patches:\n",
    "            ax.annotate('   {:}'.format(p.get_height()), (p.get_x()+0.1, p.get_height()+2))\n",
    "    plt.show()\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# plot_ITIs(ITIs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test sequence rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "stim_blocks_path=os.path.join(raw_behav_dir,'stimuli_block.txt')\n",
    "stim_blocks=pd.read_csv(stim_blocks_path,names=['sequence'])\n",
    "\n",
    "rank_path=os.path.join(raw_behav_dir,'rank.txt')\n",
    "rank=pd.read_csv(rank_path,names=['rank'])\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "for s in subjects:\n",
    "    bcsv=glob.glob(os.path.join(raw_behav_dir,'%s*' % s))\n",
    "    for file in bcsv:\n",
    "        rt=[]\n",
    "        dACC=[]\n",
    "        L_IFG=[]\n",
    "        R_IFG=[]\n",
    "        L_dlPFC=[]\n",
    "        R_dlPFC=[]\n",
    "        censor=[]\n",
    "        b=pd.read_csv(file)\n",
    "        b['sequence'] = stim_blocks\n",
    "        b['rank'] = rank \n",
    "        trials = b[ b['Stimuli'] != '+' ]\n",
    "        trials=trials[1:-2]\n",
    "        #---------------------------------##\n",
    "        file_1=os.path.join(LSS_dir,'%s.dACC_LSS_avg_file.1D' % s)\n",
    "        file_2=os.path.join(LSS_dir,'%s.L_IFG_LSS_avg_file.1D' % s)\n",
    "        file_3=os.path.join(LSS_dir,'%s.R_IFG_LSS_avg_file.1D' % s)\n",
    "        file_4=os.path.join(LSS_dir,'%s.L_dlPFC_LSS_avg_file.1D' % s)\n",
    "        file_5=os.path.join(LSS_dir,'%s.R_dlPFC_LSS_avg_file.1D' % s)\n",
    "        file_6=os.path.join(censor_dir,'msit.%s.msit_bsm.censor.1D' % s)\n",
    "        #---------------------------------##\n",
    "        ## Generate ROI variables\n",
    "        generate_roi_vars(file_1,dACC,\"dACC\")\n",
    "        generate_roi_vars(file_2,L_IFG,\"L_IFG\")\n",
    "        generate_roi_vars(file_3,R_IFG,\"R_IFG\")\n",
    "        generate_roi_vars(file_4,L_dlPFC,\"L_dlPFC\")\n",
    "        generate_roi_vars(file_5,R_dlPFC,\"R_dlPFC\")\n",
    "        censor_tps(file_6,censor,\"censor\")\n",
    "        #---------------------------------## \n",
    "        ## Interpolate missing ROI + RT data points\n",
    "        dACC = pd.Series(dACC).astype(float).interpolate()\n",
    "        R_IFG = pd.Series(R_IFG).astype(float).interpolate()\n",
    "        L_IFG = pd.Series(L_IFG).astype(float).interpolate()\n",
    "        L_dlPFC = pd.Series(L_dlPFC).astype(float).interpolate()\n",
    "        R_dlPFC = pd.Series(R_dlPFC).astype(float).interpolate()\n",
    "        #---------------------------------##\n",
    "        trials_df=pd.DataFrame({'dACC':dACC,'L_IFG':L_IFG,'R_IFG':R_IFG,\\\n",
    "                                'L_dlPFC':L_dlPFC,'R_dlPFC':R_dlPFC,\\\n",
    "                                'sequence':trials['sequence'],'rank':trials['rank'],\\\n",
    "                                'cond':trials['Condition']}) \n",
    "        # trials_df=trials_df.reset_index(drop=True)\n",
    "        \n",
    "        ROIs=['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']\n",
    "        for roi in ROIs:\n",
    "            sns.set()\n",
    "            ax=sns.lmplot(data=trials_df,x='rank',y='%s' % roi,hue='cond',markers=['o','x'])\n",
    "            plt.savefig(os.path.join(raw_behav_dir,'figs/%s.%s.conds.png' % (s,roi)))\n",
    "            ax.set(xlim=(0,18),xticks=range(1,18))\n",
    "            plt.title('%s' % s)\n",
    "            ax=sns.lmplot(data=trials_df,x='rank',y='%s' % roi)\n",
    "            ax.set(xlim=(0,18),xticks=range(1,18))\n",
    "            plt.title('%s' % s)\n",
    "            plt.savefig(os.path.join(raw_behav_dir,'figs/%s.%s.png' % (s,roi)))\n",
    "            plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
