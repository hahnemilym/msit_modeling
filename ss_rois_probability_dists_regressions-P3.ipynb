{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import glob\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as mp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.io import savemat, loadmat\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "import scipy.stats as st\n",
    "from scipy.stats import probplot, pearsonr\n",
    "from sklearn.preprocessing import scale,robust_scale\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy import interp\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dACC_group=[]\n",
    "L_dlPFC_group=[]\n",
    "R_dlPFC_group=[]\n",
    "L_IFG_group=[]\n",
    "R_IFG_group=[]\n",
    "conflict_group=[]\n",
    "adapt_group=[]\n",
    "rt_group=[]\n",
    "\n",
    "dACC_group_hc=[]\n",
    "L_dlPFC_group_hc=[]\n",
    "R_dlPFC_group_hc=[]\n",
    "L_IFG_group_hc=[]\n",
    "R_IFG_group_hc=[]\n",
    "conflict_group_hc=[]\n",
    "adapt_group_hc=[]\n",
    "rt_group_hc=[]\n",
    "\n",
    "dACC_group_pts=[]\n",
    "L_dlPFC_group_pts=[]\n",
    "R_dlPFC_group_pts=[]\n",
    "L_IFG_group_pts=[]\n",
    "R_IFG_group_pts=[]\n",
    "conflict_group_pts=[]\n",
    "adapt_group_pts=[]\n",
    "rt_group_pts=[]\n",
    "\n",
    "regions=['dACC','L_dlPFC','R_dlPFC','L_IFG','R_IFG']\n",
    "variables=['rt','adapt','conflict']\n",
    "raw_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/msit_mri_behav'\n",
    "preproc_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/completed'\n",
    "LSS_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG'\n",
    "LSS_estim_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG_estim'\n",
    "censor_dir='/Users/emilyhahn/projects/msit_modeling/censor_data'\n",
    "AIC_output='/Users/emilyhahn/projects/msit_modeling/AIC_output'\n",
    "rf_dir = '/Users/emilyhahn/projects/msit_modeling/rf_output'\n",
    "\n",
    "df=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_I=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_C=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_I_C=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})\n",
    "\n",
    "df_I_epoch_first45=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})\n",
    "df_C_epoch_first45=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SUBJ_LIST = ['hc001','hc002','hc003','hc005','hc006','hc010','hc011','hc012','hc014',\\\n",
    "             'hc015','hc017','hc019','hc021','hc028','hc031','hc032','hc033','hc034',\\\n",
    "             'hc036','hc038','hc042','pp001','pp002','pp003','pp004','pp005','pp006',\\\n",
    "             'pp010','pp011','pp012','pp013','pp015','pp016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions - Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "total_outliers=[]\n",
    "def remove_outliers(rt_var,RT_arr,sub):\n",
    "    elements=[i for i in RT_arr]\n",
    "    mean = np.nanmean(elements)\n",
    "    sd = np.nanstd(elements)\n",
    "    sd_lower = mean - 5 * sd\n",
    "    sd_upper = mean + 5 * sd\n",
    "    for x in elements:\n",
    "        if (sd_lower <= x <= sd_upper):\n",
    "            rt_var.append(x)\n",
    "        else:\n",
    "            rt_var.append('NaN')\n",
    "            print '%s\\n%.2f RT value excluded: not in range SD min (%.2f) to SD max (%.2f)' % (sub,x,sd_lower,sd_upper)\n",
    "    return\n",
    "\n",
    "def generate_roi_vars(roi_file,region,var,sub):\n",
    "    elements=[]\n",
    "    with open(roi_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            line=float(line)\n",
    "            elements.append(line)\n",
    "    mean = np.nanmean(elements)\n",
    "    sd = np.nanstd(elements)\n",
    "    sd_lower = mean - 5 * sd\n",
    "    sd_upper = mean + 5 * sd\n",
    "    for x in elements:\n",
    "        if (sd_lower <= x <= sd_upper):\n",
    "            region.append(x)\n",
    "        else:\n",
    "            region.append('NaN')\n",
    "            total_outliers.append(x)\n",
    "            print '%s\\n%.2f %s beta excluded: not in range SD min (%.2f) to SD max (%.2f)' % (sub,x,var,sd_lower,sd_upper) \n",
    "    return\n",
    "\n",
    "def censor_tps(censor_file,censor_var,var):\n",
    "    with open(censor_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            censor_var.append(line)\n",
    "    return\n",
    "\n",
    "def build_plots(ROI,variable,df_type,group,cond,sub):\n",
    "    slope, intercept, r_value, p_value, std_err = \\\n",
    "            stats.linregress(df_type['%s' % variable],df_type['%s' % ROI])\n",
    "#     if (p_value <= 1):\n",
    "    sns.set()\n",
    "    g=sns.JointGrid(x='%s' % variable, y='%s' % ROI, data=df_type)\n",
    "    g=g.plot(sns.regplot,sns.distplot)\n",
    "    lin_reg_r = lambda a, b: stats.linregress(df_type['%s' % variable], df_type['%s' % ROI])[2:4]\n",
    "    g = g.annotate(lin_reg_r, template=\"{stat}: {val:.2f} $p=$ {p:.2f}\",stat=\"$r=$\",loc=\"upper left\")                                                                        \n",
    "    plt.subplots_adjust(top=0.93)\n",
    "#     g.fig.suptitle(\"%s | %s\" % (group,cond))\n",
    "    g.fig.suptitle(\"%s | %s | %s\" % (group,cond,sub))\n",
    "#     g.savefig('/Users/emilyhahn/projects/msit_modeling/figures/%s_%s_%s_%s.png' % (ROI,variable,group,cond))\n",
    "    plt.show()\n",
    "#     else:\n",
    "#         print \"**** %s %s %s not significant ****\" % (SUBJ,ROI,cond)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Indiv and Group Data - SS output, ROI data\n",
    "    This module generates DataFrames:\n",
    "    df = ALL subjects, ALL trials\n",
    "    df_I = ALL subjects, Incongruent trials\n",
    "    df_C = ALL subjects, Congruent trials\n",
    "    df_I_C =ALL subjects, Incongruent-Congruent trials\n",
    "    df_hcs = CTRL subjects, ALL trials\n",
    "    df_pts = PSYCH subjects, ALL trials\n",
    "    df_hcs_I = CTRL subjects, Incongruent trials\n",
    "    df_pts_I = PSYCH subjects, Incongruent trials\n",
    "    df_hcs_C = CTRL subjects, Congruent trials\n",
    "    df_pts_C = PSYCH subjects, Congruent trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for SUBJ in SUBJ_LIST:\n",
    "    rt=[]\n",
    "    RT=[]\n",
    "    RT_orig=[]\n",
    "    conflict=[]\n",
    "    adapt=[]\n",
    "    dACC=[]\n",
    "    L_IFG=[]\n",
    "    R_IFG=[]\n",
    "    L_dlPFC=[]\n",
    "    R_dlPFC=[]\n",
    "    cond=[]\n",
    "    trial=[]\n",
    "    acc=[]\n",
    "    censor=[]        \n",
    "    #---------------------------------##\n",
    "    ## Configure SS variables\n",
    "    #---------------------------------##\n",
    "    mat = loadmat(os.path.join(preproc_behav_dir,'%s_msit_ss_iter250.mat') % SUBJ)\n",
    "    #---------------------------------##\n",
    "    ss_outputs_xsmt = np.expand_dims(np.array([np.concatenate(arr) \\\n",
    "                                for arr in mat['XSmt']]).squeeze(),1)\n",
    "    ss_xsmt = ss_outputs_xsmt.squeeze()\n",
    "    RT.extend([float(i) for i in np.array(mat['RT'].squeeze())])\n",
    "    remove_outliers(rt,RT,SUBJ)\n",
    "    #---------------------------------##\n",
    "    conflict.extend([float(i[0]) for i in ss_xsmt])\n",
    "    adapt.extend([float(i[1]) for i in ss_xsmt])\n",
    "    acc.extend([float(i) for i in np.array(mat['Accuracy'].squeeze())])\n",
    "    trial.extend([float(i) for i in np.array(mat['Trial'].squeeze())])\n",
    "    cond.extend([float(i) for i in np.array(mat['Interference'].squeeze())])\n",
    "    #---------------------------------##\n",
    "    ## Configure ROI variables\n",
    "    #---------------------------------##\n",
    "    ## Load indiv ROI vars\n",
    "    file_1=os.path.join(LSS_dir,'%s.dACC_LSS_avg_file.1D' % SUBJ)\n",
    "    file_2=os.path.join(LSS_dir,'%s.L_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "    file_3=os.path.join(LSS_dir,'%s.R_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "    file_4=os.path.join(LSS_dir,'%s.L_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "    file_5=os.path.join(LSS_dir,'%s.R_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "    file_6=os.path.join(censor_dir,'msit.%s.msit_bsm.censor.1D' % SUBJ)\n",
    "    #---------------------------------##\n",
    "    ## Generate ROI variables\n",
    "    generate_roi_vars(file_1,dACC,\"dACC\",SUBJ)\n",
    "    generate_roi_vars(file_2,L_IFG,\"L_IFG\",SUBJ)\n",
    "    generate_roi_vars(file_3,R_IFG,\"R_IFG\",SUBJ)\n",
    "    generate_roi_vars(file_4,L_dlPFC,\"L_dlPFC\",SUBJ)\n",
    "    generate_roi_vars(file_5,R_dlPFC,\"R_dlPFC\",SUBJ)\n",
    "    #---------------------------------##\n",
    "    censor_tps(file_6,censor,\"censor\")\n",
    "    #---------------------------------##\n",
    "    ## insert RT outliers scrubbing function here\n",
    "    #---------------------------------##\n",
    "    ## Determine group\n",
    "    s=[]\n",
    "    if 'hc' in SUBJ:\n",
    "        s.append(0)\n",
    "    elif 'pp' in SUBJ:\n",
    "        s.append(1)\n",
    "    GROUP_ARR=np.array([\"%s\" % s] * len(trial))\n",
    "    group=[float(i.strip('[]')) for i in GROUP_ARR]\n",
    "    SUBJ_ARR=np.array([\"%s\" % SUBJ] * len(trial))\n",
    "    #---------------------------------## \n",
    "    ## Scale + interpolate missing ROI + RT data points\n",
    "    ## Configure this section to statistically appropriate scaling\n",
    "    \n",
    "    dACC = pd.Series(dACC).astype(float).interpolate()\n",
    "    R_IFG = pd.Series(R_IFG).astype(float).interpolate()\n",
    "    L_IFG = pd.Series(L_IFG).astype(float).interpolate()\n",
    "    L_dlPFC = pd.Series(L_dlPFC).astype(float).interpolate()\n",
    "    R_dlPFC = pd.Series(R_dlPFC).astype(float).interpolate()\n",
    "\n",
    "    rt = preprocessing.scale(pd.Series(rt).astype(float).interpolate())\n",
    "    #---------------------------------## \n",
    "    dACC_group.append(dACC)\n",
    "    L_dlPFC_group.append(L_dlPFC)\n",
    "    R_dlPFC_group.append(R_dlPFC)\n",
    "    L_IFG_group.append(L_IFG)\n",
    "    R_IFG_group.append(R_IFG)\n",
    "    conflict_group.append(conflict)\n",
    "    adapt_group.append(adapt)\n",
    "    rt_group.append(rt)\n",
    "    #---------------------------------##\n",
    "    if 'pp' in SUBJ_ARR[0]:\n",
    "        dACC_group_pts.append(dACC)\n",
    "        L_dlPFC_group_pts.append(L_dlPFC)\n",
    "        R_dlPFC_group_pts.append(R_dlPFC)\n",
    "        L_IFG_group_pts.append(L_IFG)\n",
    "        R_IFG_group_pts.append(R_IFG)\n",
    "        conflict_group_pts.append(conflict)\n",
    "        adapt_group_pts.append(adapt)\n",
    "        rt_group_pts.append(rt)\n",
    "    elif 'hc' in SUBJ_ARR[0]:\n",
    "        dACC_group_hc.append(dACC)\n",
    "        L_dlPFC_group_hc.append(L_dlPFC)\n",
    "        R_dlPFC_group_hc.append(R_dlPFC)\n",
    "        L_IFG_group_hc.append(L_IFG)\n",
    "        R_IFG_group_hc.append(R_IFG)\n",
    "        conflict_group_hc.append(conflict)\n",
    "        adapt_group_hc.append(adapt)  \n",
    "        rt_group_hc.append(rt)\n",
    "    else:\n",
    "        \"REVIEW SUBJ ID: %s\" % SUBJ\n",
    "    ##---------------------------------##\n",
    "    ## Append subj data to master DF\n",
    "    ##---------------------------------##\n",
    "    df1=pd.DataFrame({\"group\":group,\"subject\":SUBJ_ARR,'rt':rt,'dACC':dACC,'L_IFG':L_IFG,\\\n",
    "                      'R_IFG':R_IFG,'L_dlPFC':L_dlPFC,'R_dlPFC':R_dlPFC,'trial':trial,\\\n",
    "                      'cond':cond,'acc':acc,'conflict':conflict,'adapt':adapt})\n",
    "    ##---------------------------------##\n",
    "    ## Determine AIC, BIC\n",
    "    ##---------------------------------##\n",
    "    def OLS(equation,df_type,df_name,roi,mod):\n",
    "        t_model = smf.ols(formula = '%s' % equation, data=df_type)\n",
    "        t_lin_reg = t_model.fit()\n",
    "        pvals = t_lin_reg.pvalues\n",
    "        coeff = t_lin_reg.params\n",
    "        stderr = t_lin_reg.bse\n",
    "        AIC = t_lin_reg.aic\n",
    "        conf_lower = t_lin_reg.conf_int(alpha=0.05,cols=None)[0]\n",
    "        conf_higher = t_lin_reg.conf_int(alpha=0.05,cols=None)[1]\n",
    "        results_df = pd.DataFrame(data={\"model\":equation,\"subj\":df_name,\"p_vals\":pvals,\n",
    "                                        \"β_coef\":coeff,\"std_err\":stderr,\"CI_low\":conf_lower,\n",
    "                                        \"CI_high\":conf_higher,\"AIC\":AIC})\n",
    "        results_df.index.name = 'variable'\n",
    "        results_df.reset_index(level=0, inplace=True)\n",
    "        results_df = results_df[[\"subj\",\"model\",\"variable\",\"AIC\",\"β_coef\",\"p_vals\",\"std_err\",\"CI_low\",\"CI_high\"]]  \n",
    "        results_df.to_csv(os.path.join(AIC_output,'%s_%s_%s.csv' % (df_name,roi,mod)),sep=',',index=False)\n",
    "        return\n",
    "    ##---------------------------------##\n",
    "    for cog_roi in regions:\n",
    "        \n",
    "        OLS('%s ~ 1' % cog_roi,df1,'%s' % SUBJ, cog_roi, '1')\n",
    "        OLS('%s ~ cond + 1' % cog_roi,df1,'%s' % SUBJ, cog_roi, 'cond_1')\n",
    "        OLS('%s ~ rt + 1' % cog_roi,df1,'%s' % SUBJ, cog_roi, 'rt_1')\n",
    "        OLS('%s ~ adapt + 1' % cog_roi,df1,'%s' % SUBJ, cog_roi, 'adapt_1')\n",
    "        OLS('%s ~ conflict + 1' % cog_roi,df1,'%s' % SUBJ, cog_roi,'conflict_1')\n",
    "        OLS('%s ~ adapt + conflict + 1' % cog_roi,df1,'%s' % SUBJ, cog_roi,'adapt_conflict_1')\n",
    "        \n",
    "    ##---------------------------------##\n",
    "    ##---------------------------------##\n",
    "    df=df.append(df1)\n",
    "    df1_C=df1[df1.cond == 0]\n",
    "    df1_I=df1[df1.cond == 1]\n",
    "    ##---------------------------------##\n",
    "#     conditions = ['Incongruent','Congruent']\n",
    "#     rois = ['dACC']\n",
    "\n",
    "#     for c in conditions:\n",
    "#         for region in rois:\n",
    "#             for variable in variables:\n",
    "#                 if 'pp' in SUBJ and c=='Incongruent':\n",
    "#                     build_plots('%s' % region,'%s' % variable,df1_I,'PSYCH','%s' % c,SUBJ)\n",
    "#                 elif 'pp' in SUBJ and c=='Congruent':\n",
    "#                     build_plots('%s' % region,'%s' % variable,df1_C,'PSYCH','%s' % c,SUBJ)\n",
    "#                 elif 'hc' in SUBJ and c=='Incongruent':\n",
    "#                     build_plots('%s' % region,'%s' % variable,df1_I,'CTRL','%s' % c,SUBJ)\n",
    "#                 elif 'hc' in SUBJ and c=='Congruent':\n",
    "#                     build_plots('%s' % region,'%s' % variable,df1_C,'CTRL','%s' % c,SUBJ)\n",
    "#                 else:\n",
    "#                     print '%s %s %s %s' % (g,c,region,variable)\n",
    "    ##---------------------------------##\n",
    "    df1_C_epoch_first45=df1_C[:][0:50].reset_index(drop=True).mean(axis=0,numeric_only=True) \n",
    "    df1_I_epoch_first45=df1_I[:][0:50].reset_index(drop=True).mean(axis=0,numeric_only=True)\n",
    "    ##---------------------------------##\n",
    "    df1_C=df1_C.mean(axis=0,numeric_only=True)\n",
    "    df1_I=df1_I.mean(axis=0,numeric_only=True)\n",
    "    ##---------------------------------##\n",
    "    ##---------------------------------##\n",
    "    S=group[0]\n",
    "    df1_C['subject']=SUBJ\n",
    "    df1_C['group']=S\n",
    "    df1_I['subject']=SUBJ\n",
    "    df1_I['group']=S\n",
    "#     df1_I_epoch_first45['subject']=SUBJ\n",
    "#     df1_I_epoch_first45['group']=S\n",
    "#     df1_C_epoch_first45['subject']=SUBJ\n",
    "#     df1_C_epoch_first45['group']=S\n",
    "    ##---------------------------------##\n",
    "    df_I=df_I.append(df1_I,ignore_index=True)\n",
    "    df_C=df_C.append(df1_C,ignore_index=True)\n",
    "    \n",
    "#     df_I_epoch_first45=df_I_epoch_first45.append(df1_I_epoch_first45,ignore_index=True)\n",
    "#     df_C_epoch_first45=df_C_epoch_first45.append(df1_C_epoch_first45,ignore_index=True)\n",
    "    ##---------------------------------##\n",
    "    df1_I_C=pd.DataFrame(data={\"group\":S,\"subject\":SUBJ,'rt':df1_I['rt']-df1_C['rt']},index=[1])\n",
    "    df1_I_C={\"group\":S,\"subject\":SUBJ,\\\n",
    "             'rt':df1_I['rt']-df1_C['rt'],\\\n",
    "             'dACC':df1_I['dACC']-df1_C['dACC'],\\\n",
    "             'L_IFG': df1_I['L_IFG']-df1_C['L_IFG'],\\\n",
    "             'R_IFG': df1_I['R_IFG']-df1_C['R_IFG'],\\\n",
    "             'L_dlPFC': df1_I['L_dlPFC']-df1_C['L_dlPFC'],\\\n",
    "             'R_dlPFC': df1_I['R_dlPFC']-df1_C['R_dlPFC'],\\\n",
    "             'acc': df1_I['acc']-df1_C['acc'],\\\n",
    "             'conflict': df1_I['conflict']-df1_C['conflict'],\\\n",
    "             'adapt': df1_I['adapt']-df1_C['adapt'] }\n",
    "    df_I_C=df_I_C.append(df1_I_C,ignore_index=True)\n",
    "##---------------------------------##\n",
    "## Parse DataFrames\n",
    "##---------------------------------##\n",
    "# df_hcs=df.where(df['group']==0).dropna()\n",
    "# df_pts=df.where(df['group']==1).dropna()\n",
    "# df_hcs_I=df_I.where(df_I['group']==0).dropna().reset_index(drop=True)\n",
    "# df_pts_I=df_I.where(df_I['group']==1).dropna().reset_index(drop=True)\n",
    "# df_hcs_C=df_C.where(df_C['group']==0).dropna().reset_index(drop=True)\n",
    "# df_pts_C=df_C.where(df_C['group']==1).dropna().reset_index(drop=True)\n",
    "# df_hcs_I_epoch_first45=df_I_epoch_first45.where(df_I_epoch_first45['group']==0).dropna().reset_index(drop=True)\n",
    "# df_hcs_C_epoch_first45=df_C_epoch_first45.where(df_C_epoch_first45['group']==0).dropna().reset_index(drop=True)\n",
    "# df_pts_I_epoch_first45=df_I_epoch_first45.where(df_I_epoch_first45['group']==1).dropna().reset_index(drop=True)\n",
    "# df_pts_C_epoch_first45=df_C_epoch_first45.where(df_C_epoch_first45['group']==1).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all AIC .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_files = glob.glob(AIC_output + \"/*.csv\")\n",
    "\n",
    "# frame = []\n",
    "\n",
    "# for filename in all_files:\n",
    "#     df = pd.read_csv(filename, index_col=None, header=0)\n",
    "#     frame.append(df)\n",
    "\n",
    "# df_models = pd.concat(frame, axis=0, ignore_index=True)\n",
    "\n",
    "# patient_status = []\n",
    "\n",
    "# for sub in df_models['subj']:\n",
    "#     if 'hc' in sub:\n",
    "#         patient_status.append(0)\n",
    "#     elif 'pp' in sub:\n",
    "#         patient_status.append(1)\n",
    "#     else:\n",
    "#         print \"check subj id\"\n",
    "\n",
    "# df_models['patient_status']=patient_status\n",
    "# df_models = df_models.sort_values(by=['subj','model'])\n",
    "# df_models=df_models.set_index(['subj','model','variable'])\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     display(df_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "aic_decrease_file = glob.glob(AIC_output + \"/AIC_plus_decrease_vals/*.csv\")\n",
    "\n",
    "frame_d = []\n",
    "\n",
    "for filename_d in aic_decrease_file:\n",
    "    df_d = pd.read_csv(filename_d, index_col=None, header=0)\n",
    "    frame_d.append(df_d)\n",
    "\n",
    "df_models_d = pd.concat(frame_d, axis=0, ignore_index=True)\n",
    "df_models_d = df_models_d.sort_values(by=['model','variable'])\n",
    "df_models_d = df_models_d.set_index(['model','variable'])\n",
    "\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     display(df_models_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df_models_d)\n",
    "c1_scores={}\n",
    "rand_i = np.random.randint(low=1, high=10000, size=100)\n",
    "# print rand_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def Random_Forest_Classifier(X1,X2,binary_feat_X,binary_feat_y,int_seed):\n",
    "\n",
    "    F = np.random.seed(seed = int_seed)\n",
    "    \n",
    "    ## Assign X features - [rt, cond] [conflict, adapt]\n",
    "    X1_AIC_d = df_models_d.loc[('dACC ~ %s + 1' % X1,'%s' % X1),'%s' % binary_feat_X]\n",
    "    X2_AIC_d = df_models_d.loc[('dACC ~ %s + 1' % X2,'%s' % X2),'%s' % binary_feat_X]\n",
    "    \n",
    "    X3_AIC_d = df_models_d.loc[('L_IFG ~ %s + 1' % X1,'%s' % X1),'%s' % binary_feat_X]\n",
    "    X4_AIC_d = df_models_d.loc[('L_IFG ~ %s + 1' % X2,'%s' % X2),'%s' % binary_feat_X]\n",
    "    \n",
    "    X5_AIC_d = df_models_d.loc[('R_IFG ~ %s + 1' % X1,'%s' % X1),'%s' % binary_feat_X]\n",
    "    X6_AIC_d = df_models_d.loc[('R_IFG ~ %s + 1' % X2,'%s' % X2),'%s' % binary_feat_X]\n",
    "    \n",
    "    X7_AIC_d = df_models_d.loc[('L_dlPFC ~ %s + 1' % X1,'%s' % X1),'%s' % binary_feat_X]\n",
    "    X8_AIC_d = df_models_d.loc[('L_dlPFC ~ %s + 1' % X2,'%s' % X2),'%s' % binary_feat_X]\n",
    "    \n",
    "    X9_AIC_d = df_models_d.loc[('R_dlPFC ~ %s + 1' % X1,'%s' % X1),'%s' % binary_feat_X]\n",
    "    X10_AIC_d = df_models_d.loc[('R_dlPFC ~ %s + 1' % X2,'%s' % X2),'%s' % binary_feat_X]\n",
    "    \n",
    "    ## Assign y variable - [patient status]\n",
    "    Y_pt_status = df_models_d.loc[('dACC ~ %s + 1' % X1,'%s' % X1),'%s' % binary_feat_y]\n",
    "    y=np.array(Y_pt_status)\n",
    "\n",
    "    X,X_features=np.stack((X1_AIC_d,X2_AIC_d,X3_AIC_d,X4_AIC_d,X5_AIC_d,\n",
    "                           X6_AIC_d,X7_AIC_d,X8_AIC_d,X9_AIC_d,X10_AIC_d),\n",
    "                          axis=1),['dACC_%s' % X1,'dACC_%s' % X2,'L_IFG_%s' % X1,\n",
    "                                   'L_IFG_%s' % X2,'R_IFG_%s' % X1,'R_IFG_%s' % X2,\n",
    "                                   'L_dlPFC_%s' % X1,'L_dlPFC_%s' % X2,'R_dlPFC_%s' % X1,\n",
    "                                   'R_dlPFC_%s' % X2]    \n",
    "    \n",
    "    ## Configure RF classifier\n",
    "    clf=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "    ## CV\n",
    "    folds=5\n",
    "#     cv = ShuffleSplit(n_splits=folds, test_size=0.2, random_state=F)\n",
    "    cv = StratifiedKFold(n_splits=folds, shuffle=True, random_state=F)\n",
    "    scores = cross_val_score(clf, X, y, cv=cv,scoring='balanced_accuracy',error_score='raise')  \n",
    "    \n",
    "    ## Evaluate results\n",
    "    ci = st.t.interval(0.95, len(scores)-1, loc=np.mean(scores), scale=st.sem(scores))\n",
    "    c1_scores.update({'rand_i': {int_seed:int_seed}})\n",
    "    c1_scores.update({'%s_%s' % (X1,X2): {int_seed:ci}})\n",
    "    c1_scores.update({'%s_%s_mean' % (X1,X2): {int_seed:scores.mean()}})\n",
    "    \n",
    "    ## Visulize Results\n",
    "#     print(\"AIC_ROIs_%s_%s | Scores: %s\" % (X1,X2,scores))\n",
    "#     title= \"AIC_ROIs_%s_%s | \\n mean: %.2f, ci_lower %.2f, ci_upper: %.2f\" % (X1,X2,scores.mean(), ci[0],ci[1])\n",
    "        \n",
    "#     sns.set()\n",
    "#     r_scale=np.array(range(1,folds+1))\n",
    "#     ax=sns.barplot(r_scale,scores,edgecolor=(0,0,0),yerr=scores.std(),palette='Blues_d')\n",
    "#     ax.set(xlabel='CV Fold #', ylabel='Balanced Accuracy Score')\n",
    "#     ax.set(title=title)\n",
    "#     plt.show()\n",
    "    \n",
    "    return c1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dd=[]\n",
    "dd = pd.DataFrame(columns=['conflict_adapt','rt_cond'])\n",
    "\n",
    "for s in rand_i:\n",
    "    Random_Forest_Classifier('conflict','adapt','AIC_d','patient_status',s)\n",
    "    Random_Forest_Classifier('rt','cond','AIC_d','patient_status',s)\n",
    "    c2 = pd.DataFrame.from_dict(c1_scores)\n",
    "    dd=dd.append(c2)\n",
    "    dd[['ca_ci_lower', 'ca_ci_upper']] = pd.DataFrame(dd['conflict_adapt'].tolist(),index=dd.index)\n",
    "    dd[['rc_ci_lower', 'rc_ci_upper']] = pd.DataFrame(dd['rt_cond'].tolist(),index=dd.index)\n",
    "\n",
    "# display(dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##-----------------------------------------##\n",
    "## Generate Data Structure for Visualization\n",
    "##-----------------------------------------##\n",
    "# dd = dd.drop(axis=0)\n",
    "# dd=dd.rename(columns={\"rt_cond_mean\": \"rc_mean\"})\n",
    "# dd=dd.rename(columns={\"conflict_adapt_mean\": \"ca_mean\"})\n",
    "# cols = dd.columns.tolist()\n",
    "# print cols\n",
    "# cols=['rand_i','ca_ci_lower','ca_ci_upper','ca_mean','rc_ci_lower','rc_ci_upper','rc_mean']\n",
    "# dd=dd[cols]\n",
    "\n",
    "# display(dd)\n",
    "# r_out = pd.DataFrame.to_csv(dd,os.path.join(rf_dir,'rfc_ci_mean_output.csv'),index=False)\n",
    "##----------------------##\n",
    "\n",
    "def plot_dists(df_or_path):\n",
    "    \n",
    "    dd_f = df_or_path\n",
    "    display(dd_f.describe())\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "#     ax = plt.gca()\n",
    "#     ax.set_facecolor('0.8')\n",
    "    plt.hist(dd_f.conflict_adapt_mean,bins=15,histtype=\"step\",color=['navy'])\n",
    "    plt.hist(dd_f.rt_cond_mean,bins=15,histtype=\"step\",color=['gray'])\n",
    "    \n",
    "    plt.title('')\n",
    "    plt.legend([\"State-Space Model\",\"Traditional Method\"],loc=\"upper left\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print stats.ttest_rel(dd_f.conflict_adapt_mean,dd_f.rt_cond_mean)\n",
    "    \n",
    "    return\n",
    "\n",
    "plot_dists(pd.read_csv(os.path.join(rf_dir,'rfc_ci_mean_output.csv')))\n",
    "# plot_dists(dd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for overlap between plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def overlap(start1, end1, start2, end2, rsd):\n",
    "#     \"\"\"Does the range (start1, end1) overlap with (start2, end2)?\"\"\"\n",
    "#     f = start1 <= start2 <= end1 or start1 <= end2 <= end1 or start2 <= start1 <= end2 or start2 <= end1 <= end2\n",
    "#     if f == True:\n",
    "#         print \"Seed %s: Overlap\" % rsd\n",
    "#     elif f == False:\n",
    "#         print \"Seed %s: [%s - %s] does NOT overlap w [%s - %s]\" % (rsd, start1, end1, start2, end2)\n",
    "#     return\n",
    "\n",
    "# for ca_l,ca_u,rc_l,rc_u,ix in zip(dd['ca_lower'],dd['ca_upper'],dd['rc_lower'],dd['rc_upper'],dd['index1']):\n",
    "#     overlap(ca_l,ca_u,rc_l,rc_u,ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##--------------------##   \n",
    "\n",
    "#     if 'rt' in X1:\n",
    "#         c1_scores=scores\n",
    "# #         c1_scores.append(i for i in scores)\n",
    "#     elif 'conflict' in X1:\n",
    "#         c2_scores=scores\n",
    "# #         c2_scores.append(i for i in scores)\n",
    "#     else:\n",
    "#         \"ur code is on fire fix it\"\n",
    "    \n",
    "    ## Split train/test data\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=5) \n",
    "#     print \"X train: %s\\n -----------------------\" % len(X_train)\n",
    "#     print \"X test: %s\\n -----------------------\" % len(X_test)\n",
    "\n",
    "    ## Train model\n",
    "#     clf.fit(X_train,y_train)\n",
    "\n",
    "    ## Test model\n",
    "#     y_pred=clf.predict(X_test)\n",
    "\n",
    "    ## Calculate model accuracy, confidence intervals, feature importance\n",
    "#     acc=metrics.balanced_accuracy_score(y_test, y_pred)\n",
    "#     print \"calculated accuracy: %s \" % acc\n",
    "    \n",
    "#     feature_imp = pd.Series(clf.feature_importances_,index=X_features).sort_values(ascending=False)\n",
    "#     estims = [tree.feature_importances_ for tree in clf.estimators_]\n",
    "#     ci = st.t.interval(0.95, len(estims)-1, loc=np.mean(estims), scale=st.sem(estims))\n",
    "    \n",
    "    # Organize data to plot\n",
    "#     df_results=pd.DataFrame(feature_imp,columns=['feat_imp']).reset_index()\n",
    "#     df_results=df_results.rename(columns={\"index\": \"roi\"})\n",
    "    \n",
    "    ## Determine CIs\n",
    "#     df_results['ci_lower'] = ci[0]\n",
    "#     df_results['ci_upper'] = ci[1]\n",
    "#     df_results['ci_diff'] = df_results['ci_upper']-df_results['ci_lower']\n",
    "#     df_results=df_results.reset_index(drop=True)\n",
    "    \n",
    "    ## Sort features by importance\n",
    "#     df_results=df_results.sort_values(by='feat_imp',ascending=False)\n",
    "                \n",
    "    # Plot feature importances\n",
    "#     sns.set()\n",
    "#     plt.figure()\n",
    "#     plt.title('Accuracy: %.4f' % (acc))\n",
    "    \n",
    "#     palette = plt.get_cmap('winter_r')\n",
    "#     spectrum = [1,25,50,75,100,125,150,175,200,225]\n",
    "#     plt.bar(df_results['roi'],df_results['feat_imp'],color=palette(spectrum),\n",
    "#             yerr=df_results['ci_diff'])\n",
    "    \n",
    "#     plt.xticks(df_results['roi'], rotation='vertical')\n",
    "#     plt.xlabel('Features')\n",
    "#     plt.ylabel('Feature Importance Score')\n",
    "#     plt.show()\n",
    "\n",
    "    # Save fig\n",
    "#     plt.figure()\n",
    "#     g = g.get_figure()\n",
    "#     pth = os.path.join(AIC_output,'AIC_plus_decrease_vals/figures/')\n",
    "#     g.savefig(os.path.join(pth,'%s_%s_%s_%s.png' % \n",
    "#                              (X1,X2,binary_feat_X,binary_feat_y)),\n",
    "#                 dpi=g.dpi,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     print_nested(c1_scores, prefix='')\n",
    "#     sns.barplot(list(c1_scores.keys()), list(c1_scores.values()))\n",
    "#     plt.show()\n",
    "#     c1_scores_master_dict.update(c1_scores)\n",
    "#     print c1_scores\n",
    "#     for value in c1_scores.values():\n",
    "#         print value\n",
    "#         print value[0][0]\n",
    "\n",
    "#         if key in dishes:\n",
    "#             print dishes[key]\n",
    "# print c1_scores_master_dict\n",
    "# c2_scores = Random_Forest_Classifier('conflict','adapt','AIC_d','patient_status')\n",
    "# c1_scores = Random_Forest_Classifier('rt','cond','AIC_d','patient_status')\n",
    "\n",
    "# c1_scores=[0.5,0.5,0.75,0.75,0.54166667]\n",
    "# c2_scores=[0.55,0.45,0.2,0.25,0.66666667]\n",
    "\n",
    "# print c2_scores\n",
    "# print c1_scores\n",
    "\n",
    "# t_stat, p_val = stats.ttest_ind(c1_scores,c2_scores)\n",
    "# print \"T = %.2f | P = %.2f\" % (t_stat,p_val) \n",
    "\n",
    "# F = Var(X) / Var(Y)\n",
    "# alpha = 0.05 #Or whatever you want your alpha to be.\n",
    "# p_value = scipy.stats.f.cdf(F, df1, df2)\n",
    "# if p_value > alpha:\n",
    "#     print \"not significant\"\n",
    "# elif p_value < alpha:\n",
    "#     print \"significant\"\n",
    "# else:\n",
    "#     print p_value\n",
    "    \n",
    "# scipy.stats.levene(c1_scores,c2_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check purposes only: Test an infinite amount of interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############\n",
    "#     def balanced_accuracy_score_V2(y_test, y_pred, sample_weight=None,adjusted=False):\n",
    "#         from sklearn.metrics import confusion_matrix\n",
    "#         C = confusion_matrix(y_test, y_pred, sample_weight=None)\n",
    "#         print \"confusion matrix: %s\\n\\n\" % C\n",
    "\n",
    "#         per_class = np.diag(C) / C.sum(axis=1)\n",
    "#         print \"per class: %s\\n\\n\" % per_class\n",
    "\n",
    "#         score = np.mean(per_class)\n",
    "#         print \"score: %s\\n\\n\" % score\n",
    "\n",
    "#         if adjusted:\n",
    "#             n_classes = len(per_class)\n",
    "#             chance = 1 / n_classes\n",
    "#             score -= chance\n",
    "#             score /= 1 - chance\n",
    "#             print \"score ADJUSTED: %s\\n\\n\" % score\n",
    "#         return score\n",
    "#     balanced_accuracy_score_V2(y_test, y_pred)\n",
    "############\n",
    "##---------------------------------##\n",
    "# rt_pred_ROIs_group_cond='rt ~ cond + group + dACC + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# dACC_pred_rt_ROIs_group_cond='dACC ~ cond + group + rt + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# L_IFG_pred_rt_ROIs_group_cond='L_IFG ~ cond + group + rt + dACC + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# R_IFG_pred_rt_ROIs_group_cond='R_IFG ~ cond + group + rt + L_IFG + dACC + L_dlPFC + R_dlPFC'\n",
    "# L_dlPFC_pred_rt_ROIs_group_cond='L_dlPFC ~ cond + group + rt + L_IFG + R_IFG + dACC + R_dlPFC'\n",
    "# R_dlPFC_pred_rt_ROIs_group_cond='R_dlPFC ~ cond + group + rt + L_IFG + R_IFG + L_dlPFC + dACC'\n",
    "\n",
    "# OLS(rt_pred_ROIs_group_cond,df,'ALL SUBJS | ALL DATA | %s' % rt_pred_ROIs_group_cond)\n",
    "# OLS(dACC_pred_rt_ROIs_group_cond,df,'ALL SUBJS | ALL DATA | %s' % dACC_pred_rt_ROIs_group_cond)\n",
    "# OLS(L_IFG_pred_rt_ROIs_group_cond,df,'ALL SUBJS | ALL DATA | %s' % L_IFG_pred_rt_ROIs_group_cond)\n",
    "# OLS(R_IFG_pred_rt_ROIs_group_cond,df,'ALL SUBJS | ALL DATA | %s' % R_IFG_pred_rt_ROIs_group_cond)\n",
    "# OLS(L_dlPFC_pred_rt_ROIs_group_cond,df,'ALL SUBJS | ALL DATA | %s' % L_dlPFC_pred_rt_ROIs_group_cond)\n",
    "# OLS(R_dlPFC_pred_rt_ROIs_group_cond,df,'ALL SUBJS | ALL DATA | %s' % R_dlPFC_pred_rt_ROIs_group_cond)\n",
    "\n",
    "# ##---------------------------------##\n",
    "# rt_pred_ROIs_cond='rt ~ cond + dACC + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# dACC_pred_rt_ROIs_cond='dACC ~ cond + rt + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# L_IFG_pred_rt_ROIs_cond='L_IFG ~ cond + rt + dACC + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# R_IFG_pred_rt_ROIs_cond='R_IFG ~ cond + rt + L_IFG + dACC + L_dlPFC + R_dlPFC'\n",
    "# L_dlPFC_pred_rt_ROIs_cond='L_dlPFC ~ cond + rt + L_IFG + R_IFG + dACC + R_dlPFC'\n",
    "# R_dlPFC_pred_rt_ROIs_cond='R_dlPFC ~ cond + rt + L_IFG + R_IFG + L_dlPFC + dACC'\n",
    "\n",
    "# OLS(rt_pred_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % rt_pred_ROIs_cond)\n",
    "# OLS(dACC_pred_rt_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % dACC_pred_rt_ROIs_cond)\n",
    "# OLS(L_IFG_pred_rt_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % L_IFG_pred_rt_ROIs_cond)\n",
    "# OLS(R_IFG_pred_rt_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % R_IFG_pred_rt_ROIs_cond)\n",
    "# OLS(L_dlPFC_pred_rt_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % L_dlPFC_pred_rt_ROIs_cond)\n",
    "# OLS(R_dlPFC_pred_rt_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % R_dlPFC_pred_rt_ROIs_cond)\n",
    "\n",
    "# OLS(rt_pred_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % rt_pred_ROIs_cond)\n",
    "# OLS(dACC_pred_rt_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % dACC_pred_rt_ROIs_cond)\n",
    "# OLS(L_IFG_pred_rt_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % L_IFG_pred_rt_ROIs_cond)\n",
    "# OLS(R_IFG_pred_rt_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % R_IFG_pred_rt_ROIs_cond)\n",
    "# OLS(L_dlPFC_pred_rt_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % L_dlPFC_pred_rt_ROIs_cond)\n",
    "# OLS(R_dlPFC_pred_rt_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % R_dlPFC_pred_rt_ROIs_cond)\n",
    "\n",
    "# OLS(rt_pred_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % rt_pred_ROIs_cond)\n",
    "# OLS(dACC_pred_rt_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % dACC_pred_rt_ROIs_cond)\n",
    "# OLS(L_IFG_pred_rt_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % L_IFG_pred_rt_ROIs_cond)\n",
    "# OLS(R_IFG_pred_rt_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % R_IFG_pred_rt_ROIs_cond)\n",
    "# OLS(L_dlPFC_pred_rt_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % L_dlPFC_pred_rt_ROIs_cond)\n",
    "# OLS(R_dlPFC_pred_rt_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % R_dlPFC_pred_rt_ROIs_cond)\n",
    "# ##---------------------------------##\n",
    "# rt_pred_ROIs_group='rt ~ group + dACC + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# dACC_pred_rt_ROIs_group='dACC ~ group + rt + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# L_IFG_pred_rt_ROIs_group='L_IFG ~ group + rt + dACC + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# R_IFG_pred_rt_ROIs_group='R_IFG ~ group + rt + L_IFG + dACC + L_dlPFC + R_dlPFC'\n",
    "# L_dlPFC_pred_rt_ROIs_group='L_dlPFC ~ group + rt + L_IFG + R_IFG + dACC + R_dlPFC'\n",
    "# R_dlPFC_pred_rt_ROIs_group='R_dlPFC ~ group + rt + L_IFG + R_IFG + L_dlPFC + dACC'\n",
    "\n",
    "# OLS(rt_pred_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % rt_pred_ROIs_group)\n",
    "# OLS(dACC_pred_rt_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % dACC_pred_rt_ROIs_group)\n",
    "# OLS(L_IFG_pred_rt_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % L_IFG_pred_rt_ROIs_group)\n",
    "# OLS(R_IFG_pred_rt_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % R_IFG_pred_rt_ROIs_group)\n",
    "# OLS(L_dlPFC_pred_rt_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % L_dlPFC_pred_rt_ROIs_group)\n",
    "# OLS(R_dlPFC_pred_rt_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % R_dlPFC_pred_rt_ROIs_group)\n",
    "\n",
    "# OLS(rt_pred_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % rt_pred_ROIs_group)\n",
    "# OLS(dACC_pred_rt_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % dACC_pred_rt_ROIs_group)\n",
    "# OLS(L_IFG_pred_rt_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % L_IFG_pred_rt_ROIs_group)\n",
    "# OLS(R_IFG_pred_rt_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % R_IFG_pred_rt_ROIs_group)\n",
    "# OLS(L_dlPFC_pred_rt_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % L_dlPFC_pred_rt_ROIs_group)\n",
    "# OLS(R_dlPFC_pred_rt_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % R_dlPFC_pred_rt_ROIs_group)\n",
    "\n",
    "# OLS(rt_pred_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % rt_pred_ROIs_group)\n",
    "# OLS(dACC_pred_rt_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % dACC_pred_rt_ROIs_group)\n",
    "# OLS(L_IFG_pred_rt_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % L_IFG_pred_rt_ROIs_group)\n",
    "# OLS(R_IFG_pred_rt_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % R_IFG_pred_rt_ROIs_group)\n",
    "# OLS(L_dlPFC_pred_rt_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % L_dlPFC_pred_rt_ROIs_group)\n",
    "# OLS(R_dlPFC_pred_rt_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % R_dlPFC_pred_rt_ROIs_group)\n",
    "# ##---------------------------------##\n",
    "# dACC_pred_ROIs_cond='dACC ~ cond + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# L_IFG_pred_ROIs_cond='L_IFG ~ cond + dACC + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# R_IFG_pred_ROIs_cond='R_IFG ~ cond + L_IFG + dACC + L_dlPFC + R_dlPFC'\n",
    "# L_dlPFC_pred_ROIs_cond='L_dlPFC ~ cond + L_IFG + R_IFG + dACC + R_dlPFC'\n",
    "# R_dlPFC_pred_ROIs_cond='R_dlPFC ~ cond + L_IFG + R_IFG + L_dlPFC + dACC'\n",
    "\n",
    "# OLS(dACC_pred_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % dACC_pred_ROIs_cond)\n",
    "# OLS(L_IFG_pred_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % L_IFG_pred_ROIs_cond)\n",
    "# OLS(R_IFG_pred_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % R_IFG_pred_ROIs_cond)\n",
    "# OLS(L_dlPFC_pred_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % L_dlPFC_pred_ROIs_cond)\n",
    "# OLS(R_dlPFC_pred_ROIs_cond,df,'ALL SUBJS | ALL DATA | %s' % R_dlPFC_pred_ROIs_cond)\n",
    "\n",
    "# OLS(dACC_pred_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % dACC_pred_ROIs_cond)\n",
    "# OLS(L_IFG_pred_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % L_IFG_pred_ROIs_cond)\n",
    "# OLS(R_IFG_pred_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % R_IFG_pred_ROIs_cond)\n",
    "# OLS(L_dlPFC_pred_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % L_dlPFC_pred_ROIs_cond)\n",
    "# OLS(R_dlPFC_pred_ROIs_cond,df_hcs,'CTRLS | ALL DATA | %s' % R_dlPFC_pred_ROIs_cond)\n",
    "\n",
    "# OLS(dACC_pred_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % dACC_pred_ROIs_cond)\n",
    "# OLS(L_IFG_pred_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % L_IFG_pred_ROIs_cond)\n",
    "# OLS(R_IFG_pred_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % R_IFG_pred_ROIs_cond)\n",
    "# OLS(L_dlPFC_pred_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % L_dlPFC_pred_ROIs_cond)\n",
    "# OLS(R_dlPFC_pred_ROIs_cond,df_pts,'PTS | ALL DATA | %s' % R_dlPFC_pred_ROIs_cond)\n",
    "# ##---------------------------------##\n",
    "# dACC_pred_rt_ROIs_group='dACC ~ group + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# L_IFG_pred_ROIs_group='L_IFG ~ group + dACC + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# R_IFG_pred_ROIs_group='R_IFG ~ group + L_IFG + dACC + L_dlPFC + R_dlPFC'\n",
    "# L_dlPFC_pred_ROIs_group='L_dlPFC ~ group + L_IFG + R_IFG + dACC + R_dlPFC'\n",
    "# R_dlPFC_pred_ROIs_group='R_dlPFC ~ group + L_IFG + R_IFG + L_dlPFC + dACC'\n",
    "\n",
    "# OLS(dACC_pred_rt_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % dACC_pred_rt_ROIs_group)\n",
    "# OLS(L_IFG_pred_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % L_IFG_pred_ROIs_group)\n",
    "# OLS(R_IFG_pred_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % R_IFG_pred_ROIs_group)\n",
    "# OLS(L_dlPFC_pred_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % L_dlPFC_pred_ROIs_group)\n",
    "# OLS(R_dlPFC_pred_ROIs_group,df,'ALL SUBJS | ALL DATA | %s' % R_dlPFC_pred_ROIs_group)\n",
    "\n",
    "# OLS(dACC_pred_rt_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % dACC_pred_rt_ROIs_group)\n",
    "# OLS(L_IFG_pred_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % L_IFG_pred_ROIs_group)\n",
    "# OLS(R_IFG_pred_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % R_IFG_pred_ROIs_group)\n",
    "# OLS(L_dlPFC_pred_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % L_dlPFC_pred_ROIs_group)\n",
    "# OLS(R_dlPFC_pred_ROIs_group,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % R_dlPFC_pred_ROIs_group)\n",
    "\n",
    "# OLS(dACC_pred_rt_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % dACC_pred_rt_ROIs_group)\n",
    "# OLS(L_IFG_pred_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % L_IFG_pred_ROIs_group)\n",
    "# OLS(R_IFG_pred_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % R_IFG_pred_ROIs_group)\n",
    "# OLS(L_dlPFC_pred_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % L_dlPFC_pred_ROIs_group)\n",
    "# OLS(R_dlPFC_pred_ROIs_group,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % R_dlPFC_pred_ROIs_group)\n",
    "# ##---------------------------------##\n",
    "# rt_pred_ROIs='rt ~ dACC + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# dACC_pred_rt_ROIs='dACC ~ rt + L_IFG + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# L_IFG_pred_rt_ROIs='L_IFG ~ rt + dACC + R_IFG + L_dlPFC + R_dlPFC'\n",
    "# R_IFG_pred_rt_ROIs='R_IFG ~ rt + L_IFG + dACC + L_dlPFC + R_dlPFC'\n",
    "# L_dlPFC_pred_rt_ROIs='L_dlPFC ~ rt + L_IFG + R_IFG + dACC + R_dlPFC'\n",
    "# R_dlPFC_pred_rt_ROIs='R_dlPFC ~ rt + L_IFG + R_IFG + L_dlPFC + dACC'\n",
    "\n",
    "# OLS(rt_pred_ROIs,df,'ALL SUBJS | ALL DATA | %s' % rt_pred_ROIs)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "\n",
    "# OLS(rt_pred_ROIs,df_hcs,'CTRLS | ALL DATA | %s' % rt_pred_ROIs)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "\n",
    "# OLS(rt_pred_ROIs,df_pts,'PTS | ALL DATA | %s' % rt_pred_ROIs)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "\n",
    "# OLS(rt_pred_ROIs,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % rt_pred_ROIs)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(rt_pred_ROIs,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % rt_pred_ROIs)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(rt_pred_ROIs,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % rt_pred_ROIs)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(rt_pred_ROIs,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % rt_pred_ROIs)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(rt_pred_ROIs,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % rt_pred_ROIs)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(rt_pred_ROIs,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % rt_pred_ROIs)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# ##---------------------------------##\n",
    "# dACC_pred_rt_ROIs_group_cond='dACC ~ cond + rt + group'\n",
    "# L_IFG_pred_rt_ROIs_group_cond='L_IFG ~ cond + group + rt'\n",
    "# R_IFG_pred_rt_ROIs_group_cond='R_IFG ~ cond + group + rt'\n",
    "# L_dlPFC_pred_rt_ROIs_group_cond='L_dlPFC ~ cond + group + rt'\n",
    "# R_dlPFC_pred_rt_ROIs_group_cond='R_dlPFC ~ cond + group + rt'\n",
    "\n",
    "# OLS(dACC_pred_rt_ROIs_group_cond,df,'ALL SUBJS | ALL DATA | %s' % dACC_pred_rt_ROIs_group_cond)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# ##---------------------------------##\n",
    "# rt_pred_group_cond='rt ~ cond + group'\n",
    "# dACC_pred_group_cond='dACC ~ cond + group'\n",
    "# L_IFG_pred_group_cond='L_IFG ~ cond + group'\n",
    "# R_IFG_pred_group_cond='R_IFG ~ cond + group'\n",
    "# L_dlPFC_pred_group_cond='L_dlPFC ~ cond + group'\n",
    "# R_dlPFC_pred_group_cond='R_dlPFC ~ cond + group'\n",
    "\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# ##---------------------------------##\n",
    "# dACC_pred_rt='dACC ~ rt'\n",
    "# L_IFG_pred_rt='L_IFG ~ rt'\n",
    "# R_IFG_pred_rt='R_IFG ~ rt'\n",
    "# L_dlPFC_pred_rt='L_dlPFC ~ rt'\n",
    "# R_dlPFC_pred_rt='R_dlPFC ~ rt'\n",
    "\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA | %s' % ______)\n",
    "\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA | %s' % ______)\n",
    "\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "# OLS(______,df_pts,'PTS | ALL DATA | %s' % ______)\n",
    "\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_I,'CTRLS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_I,'PTS | MEAN INCONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_hcs_C,'CTRLS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# OLS(______,df_pts_C,'PTS | MEAN CONGRUENT TRIALS | %s' % ______)\n",
    "# ##---------------------------------##\n",
    "# rt_pred_cond='rt ~ cond'\n",
    "# dACC_pred_cond='dACC ~ cond'\n",
    "# L_IFG_pred_cond='L_IFG ~ cond'\n",
    "# R_IFG_pred_cond='R_IFG ~ cond'\n",
    "# L_dlPFC_pred_cond='L_dlPFC ~ cond'\n",
    "# R_dlPFC_pred_cond='R_dlPFC ~ cond'\n",
    "\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA')\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA')\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA')\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA')\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA')\n",
    "# OLS(______,df_hcs,'CTRLS | ALL DATA')\n",
    "\n",
    "# OLS(______,df_pts,'PTS | ALL DATA')\n",
    "# OLS(______,df_pts,'PTS | ALL DATA')\n",
    "# OLS(______,df_pts,'PTS | ALL DATA')\n",
    "# OLS(______,df_pts,'PTS | ALL DATA')\n",
    "# OLS(______,df_pts,'PTS | ALL DATA')\n",
    "# OLS(______,df_pts,'PTS | ALL DATA')\n",
    "# ##---------------------------------##\n",
    "# rt_pred_group='rt ~ group'\n",
    "# dACC_pred_group='dACC ~ group'\n",
    "# L_IFG_pred_group='L_IFG ~ group'\n",
    "# R_IFG_pred_group='R_IFG ~ group'\n",
    "# L_dlPFC_pred_group='L_dlPFC ~ group'\n",
    "# R_dlPFC_pred_group='R_dlPFC ~ group'\n",
    "\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "# OLS(______,df,'ALL SUBJS | ALL DATA')\n",
    "\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS')\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS')\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS')\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS')\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS')\n",
    "# OLS(______,df_I,'ALL SUBJS | MEAN INCONGRUENT TRIALS')\n",
    "\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS')\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS')\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS')\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS')\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS')\n",
    "# OLS(______,df_C,'ALL SUBJS | MEAN CONGRUENT TRIALS')\n",
    "# ##---------------------------------##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
