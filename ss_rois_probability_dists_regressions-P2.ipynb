{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emilyhahn/anaconda2/lib/python2.7/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as mp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.io import savemat, loadmat\n",
    "# from scipy.stats import pointbiserialr\n",
    "# from matplotlib.patches import Circle\n",
    "from sklearn import datasets, linear_model, preprocessing\n",
    "from scipy.stats import probplot, pearsonr\n",
    "# from matplotlib.cbook import get_sample_data\n",
    "# from pandas.plotting import lag_plot\n",
    "# from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage,AnnotationBbox)\n",
    "# print(__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dACC_group=[]\n",
    "L_dlPFC_group=[]\n",
    "R_dlPFC_group=[]\n",
    "L_IFG_group=[]\n",
    "R_IFG_group=[]\n",
    "conflict_group=[]\n",
    "adapt_group=[]\n",
    "rt_group=[]\n",
    "\n",
    "dACC_group_hc=[]\n",
    "L_dlPFC_group_hc=[]\n",
    "R_dlPFC_group_hc=[]\n",
    "L_IFG_group_hc=[]\n",
    "R_IFG_group_hc=[]\n",
    "conflict_group_hc=[]\n",
    "adapt_group_hc=[]\n",
    "rt_group_hc=[]\n",
    "\n",
    "dACC_group_pts=[]\n",
    "L_dlPFC_group_pts=[]\n",
    "R_dlPFC_group_pts=[]\n",
    "L_IFG_group_pts=[]\n",
    "R_IFG_group_pts=[]\n",
    "conflict_group_pts=[]\n",
    "adapt_group_pts=[]\n",
    "rt_group_pts=[]\n",
    "\n",
    "regions=['dACC','L_dlPFC','R_dlPFC','L_IFG','R_IFG']\n",
    "variables=['rt','adapt','conflict']\n",
    "raw_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/msit_mri_behav'\n",
    "preproc_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/completed'\n",
    "LSS_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG'\n",
    "LSS_estim_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG_estim'\n",
    "censor_dir='/Users/emilyhahn/projects/msit_modeling/censor_data'\n",
    "\n",
    "df=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_I=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_C=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_I_C=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})\n",
    "\n",
    "df_I_epoch_first45=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})\n",
    "df_C_epoch_first45=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SUBJ_LIST = ['hc001','hc002','hc003','hc005','hc006','hc010','hc011',\\\n",
    "             'hc012','hc014','hc015','hc017','hc019','hc021','hc028',\\\n",
    "             'hc031','hc032','hc033','hc034','hc036','hc038','hc042',\\\n",
    "             'pp001','pp002','pp003','pp004','pp005','pp006','pp010',\\\n",
    "             'pp011','pp012','pp013','pp015','pp016']\n",
    "\n",
    "# SUBJ_LIST = ['hc006','hc019','hc021','hc028','hc031','hc036','pp004','pp006','pp012','pp015']\n",
    "# SUBJ_LIST = ['hc001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions - Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers(rt_var,RT_arr,sub):\n",
    "    elements=[i for i in RT_arr]\n",
    "    mean = np.nanmean(elements)\n",
    "    sd = np.nanstd(elements)\n",
    "    sd_lower = mean - 4 * sd\n",
    "    sd_upper = mean + 4 * sd\n",
    "    for x in elements:\n",
    "        if (sd_lower <= x <= sd_upper):\n",
    "            rt_var.append(x)\n",
    "        else:\n",
    "            rt_var.append('NaN')\n",
    "            print '%s\\n%.2f RT value excluded: not in range SD min (%.2f) to SD max (%.2f)' % (sub,x,sd_lower,sd_upper)\n",
    "    return\n",
    "\n",
    "def generate_roi_vars(roi_file,region,var,sub):\n",
    "    elements=[]\n",
    "    with open(roi_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            line=float(line)\n",
    "            elements.append(line)\n",
    "    mean = np.nanmean(elements)\n",
    "    sd = np.nanstd(elements)\n",
    "    sd_lower = mean - 4 * sd\n",
    "    sd_upper = mean + 4 * sd\n",
    "    for x in elements:\n",
    "        if (sd_lower <= x <= sd_upper):\n",
    "            region.append(x)\n",
    "        else:\n",
    "            region.append('NaN')\n",
    "            print '%s\\n%.2f %s beta excluded: not in range SD min (%.2f) to SD max (%.2f)' % (sub,x,var,sd_lower,sd_upper) \n",
    "    return\n",
    "\n",
    "def censor_tps(censor_file,censor_var,var):\n",
    "    with open(censor_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            censor_var.append(line)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Indiv and Group Data - SS output, ROI data\n",
    "    This module generates DataFrames:\n",
    "    df = ALL subjects, ALL trials\n",
    "    df_I = ALL subjects, Incongruent trials\n",
    "    df_C = ALL subjects, Congruent trials\n",
    "    df_I_C =ALL subjects, Incongruent-Congruent trials\n",
    "    df_hcs = CTRL subjects, ALL trials\n",
    "    df_pts = PSYCH subjects, ALL trials\n",
    "    df_hcs_I = CTRL subjects, Incongruent trials\n",
    "    df_pts_I = PSYCH subjects, Incongruent trials\n",
    "    df_hcs_C = CTRL subjects, Congruent trials\n",
    "    df_pts_C = PSYCH subjects, Congruent trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hc005\n",
      "1.62 RT value excluded: not in range SD min (0.11) to SD max (1.54)\n",
      "hc005\n",
      "8.68 dACC beta excluded: not in range SD min (-3.20) to SD max (3.42)\n",
      "hc005\n",
      "4.03 R_IFG beta excluded: not in range SD min (-3.30) to SD max (3.88)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1995249dcb13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mdf_C_epoch_first45\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_C_epoch_first45\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_C_epoch_first45\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m##---------------------------------##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mdf1_I_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"group\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"subject\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSUBJ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m     \u001b[0mdf1_I_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"group\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"subject\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mSUBJ\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'rt'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'dACC'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dACC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dACC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'L_IFG'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L_IFG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L_IFG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'R_IFG'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R_IFG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R_IFG'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'L_dlPFC'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L_dlPFC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'L_dlPFC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'R_dlPFC'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R_dlPFC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R_dlPFC'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'acc'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'conflict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conflict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'conflict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0;34m'adapt'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf1_I\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adapt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdf1_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'adapt'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mdf_I_C\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_I_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf1_I_C\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/emilyhahn/anaconda2/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/emilyhahn/anaconda2/lib/python2.7/site-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   2489\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2490\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2491\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2492\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2493\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rt'"
     ]
    }
   ],
   "source": [
    "for SUBJ in SUBJ_LIST:\n",
    "    rt=[]\n",
    "    RT=[]\n",
    "    RT_orig=[]\n",
    "    conflict=[]\n",
    "    adapt=[]\n",
    "    dACC=[]\n",
    "    L_IFG=[]\n",
    "    R_IFG=[]\n",
    "    L_dlPFC=[]\n",
    "    R_dlPFC=[]\n",
    "    cond=[]\n",
    "    trial=[]\n",
    "    acc=[]\n",
    "    censor=[]        \n",
    "    #---------------------------------##\n",
    "    ## Configure SS variables\n",
    "    #---------------------------------##\n",
    "    mat = loadmat(os.path.join(preproc_behav_dir,'%s_msit_ss_iter250.mat') % SUBJ)\n",
    "    #---------------------------------##\n",
    "    ss_outputs_xsmt = np.expand_dims(np.array([np.concatenate(arr) \\\n",
    "                                for arr in mat['XSmt']]).squeeze(),1)\n",
    "    ss_xsmt = ss_outputs_xsmt.squeeze()\n",
    "    RT.extend([float(i) for i in np.array(mat['RT'].squeeze())])\n",
    "    remove_outliers(rt,RT,SUBJ)\n",
    "    #---------------------------------##\n",
    "    conflict.extend([float(i[0]) for i in ss_xsmt])\n",
    "    adapt.extend([float(i[1]) for i in ss_xsmt])\n",
    "    acc.extend([float(i) for i in np.array(mat['Accuracy'].squeeze())])\n",
    "    trial.extend([float(i) for i in np.array(mat['Trial'].squeeze())])\n",
    "    cond.extend([float(i) for i in np.array(mat['Interference'].squeeze())])\n",
    "    #---------------------------------##\n",
    "    ## Configure ROI variables\n",
    "    #---------------------------------##\n",
    "    ## Load indiv ROI vars\n",
    "    file_1=os.path.join(LSS_dir,'%s.dACC_LSS_avg_file.1D' % SUBJ)\n",
    "    file_2=os.path.join(LSS_dir,'%s.L_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "    file_3=os.path.join(LSS_dir,'%s.R_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "    file_4=os.path.join(LSS_dir,'%s.L_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "    file_5=os.path.join(LSS_dir,'%s.R_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "    file_6=os.path.join(censor_dir,'msit.%s.msit_bsm.censor.1D' % SUBJ)\n",
    "    #---------------------------------##\n",
    "    ## Generate ROI variables\n",
    "    generate_roi_vars(file_1,dACC,\"dACC\",SUBJ)\n",
    "    generate_roi_vars(file_2,L_IFG,\"L_IFG\",SUBJ)\n",
    "    generate_roi_vars(file_3,R_IFG,\"R_IFG\",SUBJ)\n",
    "    generate_roi_vars(file_4,L_dlPFC,\"L_dlPFC\",SUBJ)\n",
    "    generate_roi_vars(file_5,R_dlPFC,\"R_dlPFC\",SUBJ)\n",
    "    #---------------------------------##\n",
    "    censor_tps(file_6,censor,\"censor\")\n",
    "    #---------------------------------##\n",
    "    ## insert RT outliers scrubbing function here\n",
    "    #---------------------------------##\n",
    "    ## Determine group\n",
    "    s=[]\n",
    "    if 'hc' in SUBJ:\n",
    "        s.append(0)\n",
    "    elif 'pp' in SUBJ:\n",
    "        s.append(1)\n",
    "    GROUP_ARR=np.array([\"%s\" % s] * len(trial))\n",
    "    group=[float(i.strip('[]')) for i in GROUP_ARR]\n",
    "    SUBJ_ARR=np.array([\"%s\" % SUBJ] * len(trial))\n",
    "    #---------------------------------## \n",
    "    ## Scale + interpolate missing ROI + RT data points\n",
    "    ## Subjects with more than two points to interpolate excluded\n",
    "\n",
    "    dACC = preprocessing.scale(pd.Series(dACC).astype(float).interpolate())\n",
    "    R_IFG = preprocessing.scale(pd.Series(R_IFG).astype(float).interpolate())\n",
    "    L_IFG = preprocessing.scale(pd.Series(L_IFG).astype(float).interpolate())\n",
    "    L_dlPFC = preprocessing.scale(pd.Series(L_dlPFC).astype(float).interpolate())\n",
    "    R_dlPFC = preprocessing.scale(pd.Series(R_dlPFC).astype(float).interpolate())\n",
    "    \n",
    "#     dACC = pd.Series(dACC).astype(float).interpolate()\n",
    "#     R_IFG = pd.Series(R_IFG).astype(float).interpolate()\n",
    "#     L_IFG = pd.Series(L_IFG).astype(float).interpolate()\n",
    "#     L_dlPFC = pd.Series(L_dlPFC).astype(float).interpolate()\n",
    "#     R_dlPFC = pd.Series(R_dlPFC).astype(float).interpolate()\n",
    "#     rt = preprocessing.scale(pd.Series(rt).astype(float).interpolate())\n",
    "    #---------------------------------## \n",
    "    dACC_group.append(dACC)\n",
    "    L_dlPFC_group.append(L_dlPFC)\n",
    "    R_dlPFC_group.append(R_dlPFC)\n",
    "    L_IFG_group.append(L_IFG)\n",
    "    R_IFG_group.append(R_IFG)\n",
    "    conflict_group.append(conflict)\n",
    "    adapt_group.append(adapt)\n",
    "    rt_group.append(rt)\n",
    "    #---------------------------------##\n",
    "    if 'pp' in SUBJ_ARR[0]:\n",
    "        dACC_group_pts.append(dACC)\n",
    "        L_dlPFC_group_pts.append(L_dlPFC)\n",
    "        R_dlPFC_group_pts.append(R_dlPFC)\n",
    "        L_IFG_group_pts.append(L_IFG)\n",
    "        R_IFG_group_pts.append(R_IFG)\n",
    "        conflict_group_pts.append(conflict)\n",
    "        adapt_group_pts.append(adapt)\n",
    "        rt_group_pts.append(rt)\n",
    "    elif 'hc' in SUBJ_ARR[0]:\n",
    "        dACC_group_hc.append(dACC)\n",
    "        L_dlPFC_group_hc.append(L_dlPFC)\n",
    "        R_dlPFC_group_hc.append(R_dlPFC)\n",
    "        L_IFG_group_hc.append(L_IFG)\n",
    "        R_IFG_group_hc.append(R_IFG)\n",
    "        conflict_group_hc.append(conflict)\n",
    "        adapt_group_hc.append(adapt)  \n",
    "        rt_group_hc.append(rt)\n",
    "    else:\n",
    "        \"REVIEW SUBJ ID: %s\" % SUBJ\n",
    "    ##---------------------------------##\n",
    "    ## Append subj data to master DF\n",
    "    ##---------------------------------##\n",
    "    df1=pd.DataFrame({\"group\":group,\"subject\":SUBJ_ARR,'rt':rt,'dACC':dACC,'L_IFG':L_IFG,\\\n",
    "                      'R_IFG':R_IFG,'L_dlPFC':L_dlPFC,'R_dlPFC':R_dlPFC,'trial':trial,\\\n",
    "                      'cond':cond,'acc':acc,'conflict':conflict,'adapt':adapt})\n",
    "    ##---------------------------------##\n",
    "    df=df.append(df1)\n",
    "    df1_C=df1[df1.cond == 0]\n",
    "    df1_I=df1[df1.cond == 1]\n",
    "    ##---------------------------------##\n",
    "    df1_C_epoch_first45=df1_C[:][0:50].reset_index(drop=True).mean(axis=0,numeric_only=True) \n",
    "    df1_I_epoch_first45=df1_I[:][0:50].reset_index(drop=True).mean(axis=0,numeric_only=True)\n",
    "    ##---------------------------------##\n",
    "    df1_C=df1_C.mean(axis=0,numeric_only=True)\n",
    "    df1_I=df1_I.mean(axis=0,numeric_only=True)\n",
    "    ##---------------------------------##\n",
    "    S=group[0]\n",
    "    df1_C['subject']=SUBJ\n",
    "    df1_C['group']=S\n",
    "    df1_I['subject']=SUBJ\n",
    "    df1_I['group']=S\n",
    "    df1_I_epoch_first45['subject']=SUBJ\n",
    "    df1_I_epoch_first45['group']=S\n",
    "    df1_C_epoch_first45['subject']=SUBJ\n",
    "    df1_C_epoch_first45['group']=S\n",
    "    ##---------------------------------##\n",
    "    df_I=df_I.append(df1_I,ignore_index=True)\n",
    "    df_C=df_C.append(df1_C,ignore_index=True)\n",
    "    \n",
    "    df_I_epoch_first45=df_I_epoch_first45.append(df1_I_epoch_first45,ignore_index=True)\n",
    "    df_C_epoch_first45=df_C_epoch_first45.append(df1_C_epoch_first45,ignore_index=True)\n",
    "    ##---------------------------------##\n",
    "    df1_I_C=pd.DataFrame(data={\"group\":S,\"subject\":SUBJ,'rt':df1_I['rt']-df1_C['rt']},index=[1])\n",
    "    df1_I_C={\"group\":S,\"subject\":SUBJ,\\\n",
    "             'rt':df1_I['rt']-df1_C['rt'],\\\n",
    "             'dACC':df1_I['dACC']-df1_C['dACC'],\\\n",
    "             'L_IFG': df1_I['L_IFG']-df1_C['L_IFG'],\\\n",
    "             'R_IFG': df1_I['R_IFG']-df1_C['R_IFG'],\\\n",
    "             'L_dlPFC': df1_I['L_dlPFC']-df1_C['L_dlPFC'],\\\n",
    "             'R_dlPFC': df1_I['R_dlPFC']-df1_C['R_dlPFC'],\\\n",
    "             'acc': df1_I['acc']-df1_C['acc'],\\\n",
    "             'conflict': df1_I['conflict']-df1_C['conflict'],\\\n",
    "             'adapt': df1_I['adapt']-df1_C['adapt'] }\n",
    "    df_I_C=df_I_C.append(df1_I_C,ignore_index=True)\n",
    "##---------------------------------##\n",
    "## Parse DataFrames\n",
    "##---------------------------------##\n",
    "df_hcs=df.where(df['group']==0).dropna()\n",
    "df_pts=df.where(df['group']==1).dropna()\n",
    "df_hcs_I=df_I.where(df_I['group']==0).dropna().reset_index(drop=True)\n",
    "df_pts_I=df_I.where(df_I['group']==1).dropna().reset_index(drop=True)\n",
    "df_hcs_C=df_C.where(df_C['group']==0).dropna().reset_index(drop=True)\n",
    "df_pts_C=df_C.where(df_C['group']==1).dropna().reset_index(drop=True)\n",
    "df_hcs_I_epoch_first45=df_I_epoch_first45.where(df_I_epoch_first45['group']==0).dropna().reset_index(drop=True)\n",
    "df_hcs_C_epoch_first45=df_C_epoch_first45.where(df_C_epoch_first45['group']==0).dropna().reset_index(drop=True)\n",
    "df_pts_I_epoch_first45=df_I_epoch_first45.where(df_I_epoch_first45['group']==1).dropna().reset_index(drop=True)\n",
    "df_pts_C_epoch_first45=df_C_epoch_first45.where(df_C_epoch_first45['group']==1).dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "sns.jointplot(x='rt', y='dACC', data=df_hcs_I,kind=\"reg\",stat_func=stats.pearsonr)\n",
    "plt.show()\n",
    "\n",
    "sns.set()\n",
    "sns.jointplot(x='rt', y='dACC', data=df_pts_I,kind=\"reg\",stat_func=stats.pearsonr)\n",
    "plt.show()\n",
    "\n",
    "# print 'PTS mean RT: %.2f' % np.mean(df_pts_I['rt'])\n",
    "# print 'HCS mean RT: %.2f' % np.mean(df_hcs_I['rt'])\n",
    "\n",
    "##---------------------------------##\n",
    "\n",
    "##---------------------------------##\n",
    "# ## PTS INCONG FIG\n",
    "# slope,intercept,r_value,p_value,std_err=stats.linregress(df_pts_I['rt'], df_pts_I['dACC'])\n",
    "# print 'rval: %s | pval: %s' % (r_value,p_value)\n",
    "# sns.set()\n",
    "# sns.jointplot(x='rt', y='dACC', data=df_pts_I,kind=\"reg\",stat_func=stats.pearsonr)\n",
    "# plt.show()\n",
    "\n",
    "## HCS INCONG FIG\n",
    "# slope,intercept,r_value,p_value,std_err=stats.linregress(df_hcs_I['rt'], df_hcs_I['dACC'])\n",
    "# print 'rval: %s | pval: %s' % (r_value,p_value)\n",
    "# sns.set()\n",
    "# sns.jointplot(x='rt', y='dACC', data=df_hcs_I,kind=\"reg\",stat_func=stats.pearsonr)\n",
    "# plt.show()\n",
    "\n",
    "## PTS CONG FIG\n",
    "# slope,intercept,r_value,p_value,std_err=stats.linregress(df_pts_C['rt'], df_pts_C['dACC'])\n",
    "# print 'rval: %s | pval: %s' % (r_value,p_value)\n",
    "# sns.set()\n",
    "# sns.jointplot(x='rt', y='dACC', data=df_pts_C,kind=\"reg\")\n",
    "# plt.show()\n",
    "# sns.jointplot(x='rt', y='dACC', data=df_pts_C,kind=\"reg\",stat_func=stats.pearsonr)\n",
    "# plt.show()\n",
    "\n",
    "# HCS CONG FIG\n",
    "# slope,intercept,r_value,p_value,std_err=stats.linregress(df_hcs_C['rt'], df_hcs_C['dACC'])\n",
    "# print 'rval: %s | pval: %s' % (r_value,p_value)\n",
    "# sns.set()\n",
    "# # # # sns.jointplot(x='rt', y='dACC', data=df_hcs_C,kind=\"reg\")\n",
    "# # # # plt.show()\n",
    "# sns.jointplot(x='rt', y='dACC', data=df_hcs_C,kind=\"reg\",stat_func=stats.pearsonr)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Main Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df['conflict_X_group']=df['conflict']*df['group']\n",
    "# df['adapt_X_group']=df['adapt']*df['group']\n",
    "# df_I['conflict_X_group']=df_I['conflict']*df_I['group']\n",
    "# df_C['conflict_X_group']=df_C['conflict']*df_C['group']\n",
    "# df_I['adapt_X_group']=df_I['adapt']*df_I['group']\n",
    "# df_C['adapt_X_group']=df_C['adapt']*df_C['group']\n",
    "# df_I['rt_X_group']=df_I['rt']*df_I['group']\n",
    "# df_C['rt_X_group']=df_C['rt']*df_C['group']\n",
    "\n",
    "# plot_OLS(df_pts_I,'rt','PTS | Incongruent')\n",
    "# plot_OLS(df_hcs_I,'rt','CTRLS | Incongruent')\n",
    "# plot_OLS(df_pts_C,'rt','PTS | Congruent')\n",
    "# plot_OLS(df_hcs_C,'rt','CTRLS | Congruent')\n",
    "\n",
    "# plot_OLS(df_pts_I,'conflict','PTS | Incongruent')\n",
    "# plot_OLS(df_hcs_I,'conflict','CTRLS | Incongruent')\n",
    "# plot_OLS(df_pts_C,'conflict','PTS | Congruent')\n",
    "# plot_OLS(df_hcs_C,'conflict','CTRLS | Congruent')\n",
    "\n",
    "# plot_OLS(df_pts_I,'adapt','PTS | Incongruent')\n",
    "# plot_OLS(df_hcs_I,'adapt','CTRLS | Incongruent')\n",
    "# plot_OLS(df_pts_C,'adapt','PTS | Congruent')\n",
    "# plot_OLS(df_hcs_C,'adapt','CTRLS | Congruent')\n",
    "\n",
    "# plot_OLS(df,'conflict_X_group','ALL SUBJS | ALL COND | dACC ~ conflict * group')\n",
    "# plot_OLS(df_I,'conflict_X_group','ALL SUBJS | Incongruent | dACC ~ conflict * group')\n",
    "# plot_OLS(df_C,'conflict_X_group','ALL SUBJS | Congruent | dACC ~ conflict * group')\n",
    "\n",
    "# plot_OLS(df_I,'adapt_X_group','ALL SUBJS | Incongruent | dACC ~ adapt * group')\n",
    "# plot_OLS(df_C,'adapt_X_group','ALL SUBJS | Congruent | dACC ~ adapt * group')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g=sns.lmplot(x='conflict',y='dACC',data=df_I,hue='group')\n",
    "# plt.show()\n",
    "\n",
    "# g=sns.lmplot(x='adapt',y='dACC',data=df_I,hue='group')\n",
    "# plt.show()\n",
    "\n",
    "# g=sns.lmplot(x='rt',y='dACC',data=df_I,hue='group')\n",
    "# plt.show()\n",
    "\n",
    "# g=sns.lmplot(x='conflict',y='dACC',data=df_C,hue='group')\n",
    "# plt.show()\n",
    "\n",
    "# g=sns.lmplot(x='adapt',y='dACC',data=df_C,hue='group')\n",
    "# plt.show()\n",
    "\n",
    "# g=sns.lmplot(x='rt',y='dACC',data=df_C,hue='group')\n",
    "# plt.show()\n",
    "\n",
    "# g=sns.lmplot(x='conflict_X_group',y='dACC',data=df,hue='group',markers=['o','x'])\n",
    "# new_title = 'Group'\n",
    "# g._legend.set_title(new_title)\n",
    "# new_labels = ['HC', 'PT']\n",
    "# for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "# ## Stats from P3 notebook below\n",
    "# plt.title(\"%s | %s\" % ('ALL TRIALS','r = 0.5612 | SD = 0.189 \\n T = 2.974 | p<0.003'))\n",
    "# plt.show()\n",
    "\n",
    "# g=sns.lmplot(x='rt_X_group',y='dACC',data=df_I,hue='group')\n",
    "# new_title = 'Group'\n",
    "# g._legend.set_title(new_title)\n",
    "# new_labels = ['HC', 'PT']\n",
    "# for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "# ## Stats from P3 notebook below\n",
    "# plt.title(\"%s | %s\" % ('INCONGRUENT','r = 0.18 | SD = 0.075 \\n T = 2.459 | p<0.016'))\n",
    "# plt.show()\n",
    "\n",
    "# g=sns.lmplot(x='rt_X_group',y='dACC',data=df_C,hue='group')\n",
    "# new_title = 'Group'\n",
    "# g._legend.set_title(new_title)\n",
    "# new_labels = ['HC', 'PT']\n",
    "# for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "# ## Stats from P3 notebook below\n",
    "# plt.title(\"%s | %s\" % ('CONGRUENT','r = 0.2127 | SD = 0.072 \\n T = -2.935 | p<0.004'))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROI ~ SS var | Linear Reg w/ Cond Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "\n",
    "# For 3d plots. This import is necessary to have 3D plotting below\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# For statistics. Requires statsmodels 5.0 or more\n",
    "from statsmodels.formula.api import ols\n",
    "# Analysis of Variance (ANOVA) on linear models\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "def lmplots_ss(df_type,sub_or_group):\n",
    "    ##---------------------------------##\n",
    "    ##  Display regplots\n",
    "    ##---------------------------------##  \n",
    "#     target_rois=['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']\n",
    "    target_rois=['dACC']\n",
    "    def make_plots(ss_var,target_rois):\n",
    "        for region in target_rois:\n",
    "            sns.set()\n",
    "            slope, intercept, r_value, p_value, std_err = \\\n",
    "            stats.linregress(df_type['%s' % ss_var],df_type['%s' % region])\n",
    "            \n",
    "            g=sns.lmplot(x=\"%s\" % ss_var,y=\"%s\" % region,data=df_type,hue=\"group\")           \n",
    "            new_title = 'Group'\n",
    "            g._legend.set_title(new_title)\n",
    "            new_labels = ['HC', 'PT']\n",
    "            for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "#             g=sns.lmplot(y=\"%s\" % ss_var,x=\"%s\" % region,data=df_type)\n",
    "            \n",
    "            plt.title(\"%s r = %.2f | p = %s\" % (sub_or_group,r_value,p_value))\n",
    "            g.set_axis_labels('%s' % ss_var, '%s' % region)\n",
    "            plt.show()\n",
    "        return\n",
    "    make_plots(\"conflict\",target_rois)  \n",
    "    make_plots(\"adapt\",target_rois)\n",
    "    make_plots('rt',target_rois)\n",
    "    return\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Group Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# lmplots_ss(df,'ALL SUBJS')\n",
    "# lmplots_ss(df_hcs,'CONTROL SUBJS')\n",
    "# lmplots_ss(df_pts,'PSYCHIATRIC SUBJS')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# lmplots_ss(df_I_C,'ALL SUBJS | Incongruent-Congruent \\n')\n",
    "# lmplots_ss(df_I,'ALL SUBJS | Incongruent \\n')\n",
    "# lmplots_ss(df_C,'ALL SUBJS | Congruent \\n ')\n",
    "lmplots_ss(df_hcs_I,'CTRL SUBJS | Incongruent \\n')\n",
    "lmplots_ss(df_hcs_C,'CTRL SUBJS | Congruent \\n')\n",
    "lmplots_ss(df_pts_I,'PSYCH SUBJS | Incongruent \\n')\n",
    "lmplots_ss(df_pts_C,'PSYCH SUBJS | Congruent \\n')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     lmplots_ss(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROI ~ ROI | Linear Reg w/ Cond Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lmplots(df_type,sub_or_group):\n",
    "    #---------------------------------##\n",
    "    #  Display regplots\n",
    "    #---------------------------------##  \n",
    "    ## Uncomment for \"Plot Group Data\"\n",
    "    #  sns.set_style(\"darkgrid\",{\"axes.facecolor\":\".85\"})\n",
    "    #  sns.set_palette(sns.hls_palette(8, l=.3, s=.8))\n",
    "    #  plt.style.use('fivethirtyeight')\n",
    "    sns.set()\n",
    "    target_rois=['L_IFG','R_IFG','L_dlPFC','R_dlPFC']\n",
    "    def make_plots(roi,target_rois):    \n",
    "        for region in target_rois:\n",
    "\n",
    "            g=sns.lmplot(x=\"%s\" % roi,y=\"%s\" % region,data=df_type,hue=\"group\",markers=[\"o\", \"x\"])\n",
    "#             g=sns.lmplot(x=\"%s\" % roi,y=\"%s\" % region,data=df_type,hue='cond')\n",
    "            plt.title(\"%s | r = %.2f | p = %s\" % (sub_or_group,r_value,p_value))\n",
    "            g.set_axis_labels('%s' % roi, '%s' % region)\n",
    "            new_title = 'Group'\n",
    "            g._legend.set_title(new_title)\n",
    "            new_labels = ['C', 'P']\n",
    "            for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "            plt.show()\n",
    "        return\n",
    "    make_plots(\"dACC\",target_rois)  \n",
    "    make_plots(\"L_IFG\",target_rois[1:])\n",
    "    make_plots(\"R_IFG\",target_rois[2:])   \n",
    "    make_plots(\"L_dlPFC\",target_rois[3:])\n",
    "    return\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Group Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# lmplots(df,'ALL SUBJS')\n",
    "# lmplots(df_hcs,'CONTROL SUBJS')\n",
    "# lmplots(df_pts,'PSYCHIATRIC SUBJS')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Data by Conditon\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# lmplots(df_I,'INCONGRUENT')\n",
    "# lmplots(df_C,'CONGRUENT')\n",
    "# lmplots(df_I_C,'INCONGRUENT-CONGRUENT')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     lmplots(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Joint Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def jpd_corr_plots(df_type1,df_type2,sub_or_group):\n",
    "    ##---------------------------------##\n",
    "    ##  Display JPD + correlations\n",
    "    ##---------------------------------## \n",
    "    target_rois=['L_IFG','R_IFG','L_dlPFC','R_dlPFC']\n",
    "    def make_joint_plots(roi,target_rois):   \n",
    "        for region in target_rois:\n",
    "            sns.set()\n",
    "            g = sns.kdeplot(df_type1[\"%s\" % roi],df_type1[\"%s\" % region],\\\n",
    "                    cmap=\"Blues\", shade=True, shade_lowest=False, cbar=True, labels='HCS')\n",
    "            g = sns.kdeplot(df_type2[\"%s\" % roi],df_type2[\"%s\" % region], \\\n",
    "                cmap=\"Oranges\", shade=False, shade_lowest=False, cbar=True, labels='PTS')\n",
    "            plt.legend()\n",
    "            plt.title(\"oranges = patients | blues = controls\")\n",
    "            plt.show()       \n",
    "        return\n",
    "    make_joint_plots(\"dACC\",target_rois)  \n",
    "    make_joint_plots(\"L_IFG\",target_rois[1:])\n",
    "    make_joint_plots(\"R_IFG\",target_rois[2:])   \n",
    "    make_joint_plots(\"L_dlPFC\",target_rois[3:])\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot ALL Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# jpd_corr_plots(df_hcs,df_pts,'ALL SUBJS')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# jpd_corr_plots(df_hcs_I,df_pts_I,'Incongruent ALL SUBJS')\n",
    "# jpd_corr_plots(df_hcs_C,df_pts_C,'Congruent ALL SUBJS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint plots and pair grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pairgrid_plot(df_type,sub_or_group):\n",
    "    sns.set()\n",
    "    sns.axes_style('white')\n",
    "    palette=sns.color_palette(\"Paired\", 2)\n",
    "    vars=[\"dACC\",\"L_IFG\",\"R_IFG\",\"L_dlPFC\",\"R_dlPFC\",\"conflict\",\"adapt\",\"rt\"]\n",
    "#     g = sns.PairGrid(df_type,vars=vars,hue='subject')\n",
    "    g = sns.PairGrid(df_type,vars=vars,hue='cond')\n",
    "    g.map(sns.regplot)\n",
    "    g.add_legend()\n",
    "    plt.title('%s' % sub_or_group)\n",
    "    plt.show()\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot ALL Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# pairgrid_plot(df,'ALL SUBJS')\n",
    "# pairgrid_plot(df_hcs,'CONTROL SUBJS')\n",
    "# pairgrid_plot(df_pts,'PSYCHIATRIC SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# pairgrid_plot(df_I,'Incongruent ALL SUBJS')\n",
    "# pairgrid_plot(df_hcs_I,'Incongruent CONTROL SUBJS')\n",
    "# pairgrid_plot(df_pts_I,'Incongruent PSYCHIATRIC SUBJS')\n",
    "# pairgrid_plot(df_C,'Congruent ALL SUBJS')\n",
    "# pairgrid_plot(df_hcs_C,'Congruent CONTROL SUBJS')\n",
    "# pairgrid_plot(df_pts_C,'Congruent PSYCHIATRIC SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     pairgrid_plot(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def df_dist(regions,df_type,subj_group,behav_vars):\n",
    "    for region in regions:\n",
    "        sns.distplot(df_type['%s' % region],label='%s' % region)\n",
    "    plt.legend()\n",
    "    plt.title(subj_group)\n",
    "    plt.xlabel('ALL ROIs')\n",
    "    plt.show()\n",
    "    for region in regions:\n",
    "        sns.distplot(df_type['%s' % region])\n",
    "        plt.title(subj_group)\n",
    "        plt.show()\n",
    "    for var in variables:\n",
    "        sns.distplot(df_type['%s' % var],label='%s' % var)\n",
    "#         sns.distplot(df_type['%s' % var], kde=False, fit=stats.gamma)\n",
    "    plt.legend()\n",
    "    plt.title(subj_group)\n",
    "    plt.xlabel('ALL Variables')\n",
    "    plt.show()\n",
    "    for var in variables:\n",
    "        sns.distplot(df_type['%s' % var])\n",
    "#         sns.distplot(df_type['%s' % var], kde=False, fit=stats.gamma)\n",
    "        plt.title(subj_group)\n",
    "        plt.show()\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# df_dist(regions,df_I,'Incongruent ALL SUBJS',variables)\n",
    "# df_dist(regions,df_hcs_I,'Incongruent CONTROL SUBJS',variables)\n",
    "# df_dist(regions,df_pts_I,'Incongruent PSYCHIATRIC SUBJS',variables)\n",
    "# df_dist(regions,df_C,'Congruent ALL SUBJS',variables)\n",
    "# df_dist(regions,df_hcs_C,'Congruent CONTROL SUBJS',variables)\n",
    "# df_dist(regions,df_pts_C,'Congruent PSYCHIATRIC SUBJS',variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Mixed Effects Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mixed_LM(df_type,sub_or_group):\n",
    "#     for beta in ['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']:\n",
    "#         for ss_v in ['conflict','adapt','rt']:\n",
    "#             md = smf.mixedlm('%s ~ %s' % (reg,ss_v),data=df_type,groups=\"group\")\n",
    "#             mdf = md.fit()\n",
    "#             print(mdf.summary())\n",
    "#     return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# mixed_LM(df,'ALL SUBJS')\n",
    "# mixed_LM(df_hcs,'CONTROL SUBJS')\n",
    "# mixed_LM(df_pts,'PSYCHIATRIC SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *DEPRECIATED: Modify this section to reflect updated ss model*\n",
    "\n",
    "The MSIT state space model is as follows:\n",
    "\n",
    "$$\n",
    "RT(k) = \\beta_0 + \\beta_1 * Interference + X_{ss}(k)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "X_{ss}(k) = X_{ss}(k - 1) + W\n",
    "$$\n",
    "\n",
    "Interference is 1 if the current trial k is an incongruent trial and 0 if it is a congruent trial."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##---------------------------------##\n",
    "##----->> SS Notes:\n",
    "##---------------------------------##\n",
    "SS Output:\n",
    "- XSmt = smoothing result - mean\n",
    "- SSmt = smoothing result - variance\n",
    "##---------------------------------##\n",
    "2 state vars - variance, covariance components\n",
    "- XPos = filtering result - mean\n",
    "- SPos = filtering result - variance\n",
    "##---------------------------------##\n",
    "- ML = value of E-step maximization\n",
    "- EYn = prdiction of the Yn\n",
    "- Param = updated model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Depreciated but maybe use later\n",
    "\n",
    "# def plot_OLS(df_type,variable,group_cond):\n",
    "#     sns.set()\n",
    "#     g = sns.lmplot('%s' % variable,'dACC',data=df_type,hue='cond')\n",
    "#     new_labels = ['C', 'I']\n",
    "#     for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "\n",
    "#     g = sns.JointGrid('%s' % variable,'dACC',data=df_type,ratio=1000)\n",
    "#     g.plot_joint(sns.regplot)\n",
    "#     g.plot(sns.regplot, sns.distplot)\n",
    "#     g.annotate(stats.pearsonr)\n",
    "#     g.ax_marg_x.set_axis_off()\n",
    "#     g.ax_marg_y.set_axis_off()\n",
    "#     slope, intercept, r_value, p_value, std_err = \\\n",
    "#     stats.linregress(df_type['%s' % variable],df_type['dACC'])\n",
    "#     plt.title('%s | r val: %.3f | pval: %.3f' % (group_cond,r_value,p_value))\n",
    "#     plt.show()\n",
    "#     return\n",
    "\n",
    "# from scipy import stats\n",
    "# def plot_OLS(df_type,variable,group_cond):\n",
    "#     sns.set()\n",
    "#     g=[]\n",
    "#     g = sns.JointGrid(df_type['%s' % variable],df_type['dACC'],ratio=1000)\n",
    "# # #     g = sns.JointGrid(df_type['%s' % variable],df_type['dACC'],ratio=1000)\n",
    "#     g.plot_joint(sns.regplot)\n",
    "#     g.annotate(stats.pearsonr)\n",
    "# #     g.ax_marg_x.set_axis_off()\n",
    "# #     g.ax_marg_y.set_axis_off()\n",
    "#     plt.title('%s' % group_cond)\n",
    "#     plt.show()\n",
    "#     return\n",
    "\n",
    "#     plot_OLS(df1,'rt','%s' % SUBJ)\n",
    "#     plot_OLS(df1,'adapt','%s' % SUBJ)\n",
    "#     plot_OLS(df1,'conflict','%s' % SUBJ)\n",
    "    \n",
    "#     plot_OLS(df1_I,'rt','%s | Incongruent' % SUBJ)\n",
    "#     plot_OLS(df1_I,'conflict','%s | Incongruent' % SUBJ)\n",
    "#     plot_OLS(df1_I,'adapt','%s | Incongruent' % SUBJ)\n",
    "    \n",
    "#     plot_OLS(df1_C,'rt','%s | Congruent' % SUBJ)\n",
    "#     plot_OLS(df1_C,'conflict','%s | Congruent' % SUBJ)\n",
    "#     plot_OLS(df1_C,'adapt','%s | Congruent' % SUBJ)\n",
    "\n",
    "\n",
    "#---------------------------------##\n",
    "# Substitute Group Identifiers\n",
    "#---------------------------------##\n",
    "# df=df.replace({'group': '1'}, 0)\n",
    "# df=df.replace({'group': '2'}, 1)\n",
    "\n",
    "# df_I_C=df_I_C.replace({'group': '1'}, 0)\n",
    "# df_I_C=df_I_C.replace({'group': '2'}, 1)\n",
    "\n",
    "# df_I=df_I.replace({'group': '1'}, 0)\n",
    "# df_I=df_I.replace({'group': '2'}, 1)\n",
    "\n",
    "# df_C=df_C.replace({'group': '1'}, 0)\n",
    "# df_C=df_C.replace({'group': '2'}, 1)\n",
    "\n",
    "# df_I_epoch_first45=df_I_epoch_first45.replace({'group': '1'}, 0)\n",
    "# df_I_epoch_first45=df_I_epoch_first45.replace({'group': '2'}, 1)\n",
    "\n",
    "# df_C_epoch_first45=df_C_epoch_first45.replace({'group': '1'}, 0)\n",
    "# df_C_epoch_first45=df_C_epoch_first45.replace({'group': '2'}, 1)\n",
    "\n",
    "#---------------------------------##\n",
    "# Remove Trial label\n",
    "#---------------------------------##\n",
    "# df_C=df_C.drop(labels=['trial'],axis=1)\n",
    "# df_I=df_I.drop(labels=['trial'],axis=1)\n",
    "# df_I_epoch_first45=df_I_epoch_first45.drop(labels=['trial'],axis=1)\n",
    "# df_C_epoch_first45=df_C_epoch_first45.drop(labels=['trial'],axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
