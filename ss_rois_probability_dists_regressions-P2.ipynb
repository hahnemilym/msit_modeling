{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from pandas import read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot as mp\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.io import savemat, loadmat\n",
    "from scipy.stats import pointbiserialr\n",
    "from matplotlib.patches import Circle\n",
    "from sklearn import datasets, linear_model\n",
    "from scipy.stats import probplot, pearsonr\n",
    "from matplotlib.cbook import get_sample_data\n",
    "from pandas.plotting import lag_plot\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from sklearn.preprocessing import scale \n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "from matplotlib.offsetbox import (TextArea, DrawingArea, OffsetImage,AnnotationBbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dACC_group=[]\n",
    "L_dlPFC_group=[]\n",
    "R_dlPFC_group=[]\n",
    "L_IFG_group=[]\n",
    "R_IFG_group=[]\n",
    "conflict_group=[]\n",
    "adapt_group=[]\n",
    "rt_group=[]\n",
    "\n",
    "dACC_group_hc=[]\n",
    "L_dlPFC_group_hc=[]\n",
    "R_dlPFC_group_hc=[]\n",
    "L_IFG_group_hc=[]\n",
    "R_IFG_group_hc=[]\n",
    "conflict_group_hc=[]\n",
    "adapt_group_hc=[]\n",
    "rt_group_hc=[]\n",
    "\n",
    "dACC_group_pts=[]\n",
    "L_dlPFC_group_pts=[]\n",
    "R_dlPFC_group_pts=[]\n",
    "L_IFG_group_pts=[]\n",
    "R_IFG_group_pts=[]\n",
    "conflict_group_pts=[]\n",
    "adapt_group_pts=[]\n",
    "rt_group_pts=[]\n",
    "\n",
    "regions=['dACC','L_dlPFC','R_dlPFC','L_IFG','R_IFG']\n",
    "variables=['rt','adapt','conflict']\n",
    "raw_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/msit_mri_behav'\n",
    "preproc_behav_dir='/Users/emilyhahn/projects/msit_modeling/behavior_preproc/completed'\n",
    "LSS_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG'\n",
    "LSS_estim_dir='/Users/emilyhahn/projects/msit_modeling/LSS_AVG_estim'\n",
    "censor_dir='/Users/emilyhahn/projects/msit_modeling/censor_data'\n",
    "\n",
    "df=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_I=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_C=pd.DataFrame({'group':[],'subject':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'trial':[],'cond':[],'acc':[],'rt':[],'conflict':[],'adapt':[]})\n",
    "df_I_C=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[],'dACC':[],'L_IFG':[],'R_IFG':[],'L_dlPFC':[],'R_dlPFC':[],'acc':[],'conflict':[],'adapt':[]})\n",
    "# df_I_C=pd.DataFrame({\"group\":[],\"subject\":[],'rt':[]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SUBJ_LIST = ['hc001','hc002','hc003','hc004','hc005','hc006','hc009','hc010','hc011',\\\n",
    "#              'hc012','hc014','hc015','hc017','hc018','hc019','hc021','hc023','hc028',\\\n",
    "#              'hc031','hc032','hc033','hc034','hc036','hc038','hc042']\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# SUBJ_LIST = ['pp001','pp002','pp003','pp004','pp005','pp006','pp007','pp008',\\\n",
    "#              'pp010','pp011','pp012','pp013','pp015','pp016']\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## hc031 -- resolve NaN issue for rt\n",
    "SUBJ_LIST = ['hc001','hc002','hc003','hc004','hc005','hc006','hc009','hc010','hc011',\\\n",
    "             'hc012','hc014','hc015','hc017','hc018','hc019','hc021','hc023','hc028',\\\n",
    "             'hc032','hc033','hc034','hc036','hc038','hc042','pp001','pp002',\\\n",
    "             'pp003','pp004','pp005','pp006','pp007','pp008','pp010','pp011','pp012',\\\n",
    "             'pp013','pp015','pp016']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Functions - Data Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize(arr): return (arr - arr.min()) / (arr.max() - arr.min())\n",
    "\n",
    "def generate_roi_vars(roi_file,region,var):\n",
    "    with open(roi_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            line=float(line)\n",
    "            if -5<line<5 and line!=0:\n",
    "                region.append(line)\n",
    "            else:\n",
    "                region.append('NaN')\n",
    "#                 print \"%s beta exlcuded for %s\" % (line,roi_file)\n",
    "    return\n",
    "def censor_tps(censor_file,censor_var,var):\n",
    "    with open(censor_file, 'r') as file:\n",
    "        for line in file:\n",
    "            line=line.strip()\n",
    "            censor_var.append(line)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assemble Indiv and Group Data - SS output, ROI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for SUBJ in SUBJ_LIST:\n",
    "    rt=[]\n",
    "    conflict=[]\n",
    "    adapt=[]\n",
    "    dACC=[]\n",
    "    L_IFG=[]\n",
    "    R_IFG=[]\n",
    "    L_dlPFC=[]\n",
    "    R_dlPFC=[]\n",
    "    cond=[]\n",
    "    trial=[]\n",
    "    acc=[]\n",
    "    censor=[]        \n",
    "    #---------------------------------##\n",
    "    ## Configure SS variables\n",
    "    #---------------------------------##\n",
    "    mat = loadmat(os.path.join(preproc_behav_dir,'%s_msit_ss_iter250.mat') % SUBJ)\n",
    "    #---------------------------------##\n",
    "    ss_outputs_xsmt = np.expand_dims(np.array([np.concatenate(arr) \\\n",
    "                                for arr in mat['XSmt']]).squeeze(),1)\n",
    "    ss_xsmt = normalize(ss_outputs_xsmt.squeeze())\n",
    "    rt.extend([float(i) for i in np.array(mat['RT'].squeeze())])\n",
    "#     if SUBJ=='hc031':\n",
    "#         rt[rt == 'nan'] = 'NaN'\n",
    "    #---------------------------------##\n",
    "    conflict.extend([float(i[0]) for i in ss_xsmt])\n",
    "    adapt.extend([float(i[1]) for i in ss_xsmt])\n",
    "    acc.extend([float(i) for i in np.array(mat['Accuracy'].squeeze())])\n",
    "    trial.extend([float(i) for i in np.array(mat['Trial'].squeeze())])\n",
    "    cond.extend([float(i) for i in np.array(mat['Interference'].squeeze())])\n",
    "    #---------------------------------##\n",
    "    ## Configure ROI variables\n",
    "    #---------------------------------##\n",
    "    ## Load indiv ROI vars\n",
    "    file_1=os.path.join(LSS_dir,'%s.dACC_LSS_avg_file.1D' % SUBJ)\n",
    "    file_2=os.path.join(LSS_dir,'%s.L_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "    file_3=os.path.join(LSS_dir,'%s.R_IFG_LSS_avg_file.1D' % SUBJ)\n",
    "    file_4=os.path.join(LSS_dir,'%s.L_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "    file_5=os.path.join(LSS_dir,'%s.R_dlPFC_LSS_avg_file.1D' % SUBJ)\n",
    "    file_6=os.path.join(censor_dir,'msit.%s.msit_bsm.censor.1D' % SUBJ)\n",
    "    #---------------------------------##\n",
    "    ## Generate ROI variables\n",
    "    generate_roi_vars(file_1,dACC,\"dACC\")\n",
    "    generate_roi_vars(file_2,L_IFG,\"L_IFG\")\n",
    "    generate_roi_vars(file_3,R_IFG,\"R_IFG\")\n",
    "    generate_roi_vars(file_4,L_dlPFC,\"L_dlPFC\")\n",
    "    generate_roi_vars(file_5,R_dlPFC,\"R_dlPFC\")\n",
    "    censor_tps(file_6,censor,\"censor\")\n",
    "    #---------------------------------##\n",
    "    ## Determine group\n",
    "    s=[]\n",
    "    if 'hc' in SUBJ:\n",
    "        s.append(1)\n",
    "    elif 'pp' in SUBJ:\n",
    "        s.append(2)\n",
    "    GROUP_ARR=np.array([\"%s\" % s] * len(trial))\n",
    "    group=[i.strip('[]') for i in GROUP_ARR]\n",
    "    SUBJ_ARR=np.array([\"%s\" % SUBJ] * len(trial))\n",
    "    #---------------------------------## \n",
    "    ## Interpolate missing ROI + RT data points\n",
    "    dACC = normalize(pd.Series(dACC).astype(float).interpolate())\n",
    "    R_IFG = normalize(pd.Series(R_IFG).astype(float).interpolate())\n",
    "    L_IFG = normalize(pd.Series(L_IFG).astype(float).interpolate())\n",
    "    L_dlPFC = normalize(pd.Series(L_dlPFC).astype(float).interpolate())\n",
    "    R_dlPFC = normalize(pd.Series(R_dlPFC).astype(float).interpolate())\n",
    "    rt = normalize(pd.Series(rt).astype(float).interpolate())\n",
    "    #---------------------------------## \n",
    "    dACC_group.append(np.log(dACC))\n",
    "    L_dlPFC_group.append(np.log(L_dlPFC))\n",
    "    R_dlPFC_group.append(np.log(R_dlPFC))\n",
    "    L_IFG_group.append(np.log(L_IFG))\n",
    "    R_IFG_group.append(np.log(R_IFG))\n",
    "    conflict_group.append(np.log(conflict))\n",
    "    adapt_group.append(np.log(adapt))\n",
    "    rt_group.append(np.log(rt))\n",
    "    #---------------------------------##\n",
    "    if 'pp' in SUBJ_ARR[0]:\n",
    "        dACC_group_pts.append(dACC)\n",
    "        L_dlPFC_group_pts.append(L_dlPFC)\n",
    "        R_dlPFC_group_pts.append(R_dlPFC)\n",
    "        L_IFG_group_pts.append(L_IFG)\n",
    "        R_IFG_group_pts.append(R_IFG)\n",
    "        conflict_group_pts.append(conflict)\n",
    "        adapt_group_pts.append(adapt)\n",
    "        rt_group_pts.append(rt)\n",
    "    elif 'hc' in SUBJ_ARR[0]:\n",
    "        dACC_group_hc.append(dACC)\n",
    "        L_dlPFC_group_hc.append(L_dlPFC)\n",
    "        R_dlPFC_group_hc.append(R_dlPFC)\n",
    "        L_IFG_group_hc.append(L_IFG)\n",
    "        R_IFG_group_hc.append(R_IFG)\n",
    "        conflict_group_hc.append(conflict)\n",
    "        adapt_group_hc.append(adapt)  \n",
    "        rt_group_hc.append(rt)\n",
    "    else:\n",
    "        \"REVIEW SUBJ ID: %s\" % SUBJ\n",
    "    ##---------------------------------##\n",
    "    ## Append subj data to master DF\n",
    "    ##---------------------------------##\n",
    "    df1=pd.DataFrame({\"group\":group,\"subject\":SUBJ_ARR,'rt':rt,'dACC':dACC,\\\n",
    "                      'L_IFG':L_IFG,'R_IFG':R_IFG,'L_dlPFC':L_dlPFC,\\\n",
    "                      'R_dlPFC':R_dlPFC,'trial':trial,'cond':cond,'acc':acc,\\\n",
    "                      'conflict':conflict,'adapt':adapt})\n",
    "    ##---------------------------------##\n",
    "    df=df.append(df1)\n",
    "    df1_C=df1[df1.cond == 0]\n",
    "    df1_I=df1[df1.cond == 1]\n",
    "    ##---------------------------------##\n",
    "    S=group[0]\n",
    "    df1_C=df1_C.mean(axis=0,numeric_only=True)\n",
    "    df1_C['subject']=SUBJ\n",
    "    df1_C['group']=S\n",
    "    df1_I=df1_I.mean(axis=0,numeric_only=True)\n",
    "    df1_I['subject']=SUBJ\n",
    "    df1_I['group']=S\n",
    "    ##---------------------------------##\n",
    "    df_I=df_I.append(df1_I,ignore_index=True)\n",
    "    df_C=df_C.append(df1_C,ignore_index=True)\n",
    "    ##---------------------------------##\n",
    "#     df1_I_C=pd.DataFrame(data={\"group\":S,\"subject\":SUBJ,'rt':df1_I['rt']-df1_C['rt']},index=[1])\n",
    "    df1_I_C={\"group\":S,\"subject\":SUBJ,\\\n",
    "             'rt':df1_I['rt']-df1_C['rt'],\\\n",
    "             'dACC':df1_I['dACC']-df1_C['dACC'],\\\n",
    "             'L_IFG': df1_I['L_IFG']-df1_C['L_IFG'],\\\n",
    "             'R_IFG': df1_I['R_IFG']-df1_C['R_IFG'],\\\n",
    "             'L_dlPFC': df1_I['L_dlPFC']-df1_C['L_dlPFC'],\\\n",
    "             'R_dlPFC': df1_I['R_dlPFC']-df1_C['R_dlPFC'],\\\n",
    "             'acc': df1_I['acc']-df1_C['acc'],\\\n",
    "             'conflict': df1_I['conflict']-df1_C['conflict'],\\\n",
    "             'adapt': df1_I['adapt']-df1_C['adapt'] }\n",
    "    df_I_C=df_I_C.append(df1_I_C,ignore_index=True)\n",
    "    \n",
    "print([i for i in df_I_C['rt']])\n",
    "##---------------------------------##\n",
    "df_C=df_C.drop(labels=['trial'],axis=1)\n",
    "df_I=df_I.drop(labels=['trial'],axis=1)\n",
    "##---------------------------------##\n",
    "## Parse DataFrames\n",
    "##---------------------------------##\n",
    "df_hcs=df.where(df['group']=='1')\n",
    "df_hcs=df_hcs.dropna()\n",
    "df_pts=df.where(df['group']=='2')\n",
    "df_pts=df_pts.dropna()\n",
    "\n",
    "df_hcs_I=df_I.where(df_I['group']=='1')\n",
    "df_hcs_I=df_hcs_I.dropna()\n",
    "df_pts_I=df_I.where(df_I['group']=='2')\n",
    "df_pts_I=df_pts_I.dropna()\n",
    "\n",
    "df_hcs_C=df_C.where(df_C['group']=='1')\n",
    "df_hcs_C=df_hcs_C.dropna()\n",
    "df_pts_C=df_C.where(df_C['group']=='2')\n",
    "df_pts_C=df_pts_C.dropna()\n",
    "##---------------------------------##\n",
    "print '''DataFrames generated to plot: \\n \n",
    "df = ALL subjects, ALL trials\n",
    "df_I = ALL subjects, Incongruent trials\n",
    "df_C = ALL subjects, Congruent trials\n",
    "df_I_C =ALL subjects, Incongruent-Congruent trials\n",
    "df_hcs = CTRL subjects, ALL trials\n",
    "df_pts = PSYCH subjects, ALL trials\n",
    "df_hcs_I = CTRL subjects, Incongruent trials\n",
    "df_pts_I = PSYCH subjects, Incongruent trials\n",
    "df_hcs_C = CTRL subjects, Congruent trials\n",
    "df_pts_C = PSYCH subjects, Congruent trials'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "('Coefficients: \\n', array([1.69887608]))\n",
      "Mean squared error: 0.06\n",
      "Variance score: -14.53\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWQAAADuCAYAAAAOR30qAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxz3r0AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(__doc__)\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# from sklearn import datasets, linear_model\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# ## Load dataset\n",
    "# df_I_C = pd.DataFrame()\n",
    "# df_I_C['rt']=[0.38771715323451417, 0.24841261910534074, 0.1807567435524972, \\\n",
    "#               0.15379757490187662, 0.22698247933846483, 0.2925377928282689, \\\n",
    "#               0.1666398766923059, 0.17057953179010393, 0.2180424900158954, \n",
    "#               0.32640840145725697, 0.2450218810120618, 0.16269463911904347, \\\n",
    "#               0.23538445380851836, 0.2880961369377016, 0.3304359441596386, \\\n",
    "#               0.16745688050789864, 0.2968876370430828, 0.24176769993010952, \\\n",
    "#               0.2069469231104322, 0.2803158108786812, 0.19083033938307553, \\\n",
    "#               0.2747344163899315, 0.19186828350936214, 0.2528347332401746, \\\n",
    "#               0.3149762314520013, 0.22921054682219874, 0.13627135911239702, \\\n",
    "#               0.38697304048233805, 0.31847819501590136, 0.3221989882294187, \\\n",
    "#               0.2527230612171226, 0.21106674991039145, 0.27466700468239913, \\\n",
    "#               0.17734799222757974, 0.3235444720080656, 0.27581511803130426, \\\n",
    "#               0.16171018762941128, 0.26945388437192874]\n",
    "# df_I_C['dACC']=[0.031932603251586755, -0.029252480720662555, 0.012125593873599405, \\\n",
    "#                 -0.005011969612112699, 0.010431609781894613, -0.03011551384948513, \\\n",
    "#                 0.044590452939163, 0.0017977157964697565, 0.02686214500581885, \\\n",
    "#                 0.016975529201946893, -0.012563490974991098, 0.000823254635602455, \\\n",
    "#                 0.05048616804368211, -0.004206776901867076, -0.017105154648771714, \\\n",
    "#                 -0.03598211082842062, 0.009346715889199608, -0.0011294658211800646, \\\n",
    "#                 -0.007692930163520073, 0.05892336321901798, 0.005173288768336615, \\\n",
    "#                 -0.004421413989281531, 0.025115467496002852, -0.018118952949897738, \\\n",
    "#                 0.00420941378669254, 0.029884073155729995, 0.017274684159841014, \\\n",
    "#                 0.01277972923041465, -0.02462936648647307, 0.009784723512831106, \\\n",
    "#                 0.010557574398966874, 0.005749410382607956, 0.06790347945180364, \\\n",
    "#                 0.015358057618862886, 0.025908268383455668, -0.006385302844275742, \\\n",
    "#                 0.01258024725553103, -0.024555169784802322]\n",
    "\n",
    "# ## Use only one feature\n",
    "# X = np.array([i for i in df_I_C['dACC']]).reshape(-1,1)\n",
    "# y = df_I_C\n",
    "\n",
    "# ## Split data into training/testing sets\n",
    "# X_train = X[:-20]\n",
    "# X_test = X[-20:]\n",
    "\n",
    "# ## Split the targets into training/testing sets\n",
    "# y_train = y.rt[:-20]\n",
    "# y_test = y.rt[-20:]\n",
    "\n",
    "# ## Create linear regression object\n",
    "# regr = linear_model.LinearRegression(fit_intercept=False)\n",
    "\n",
    "# ## Train the model using the training sets\n",
    "# regr.fit(X_train, y_train)\n",
    "\n",
    "# ## Make predictions using the testing set\n",
    "# y_pred = regr.predict(X_test)\n",
    "\n",
    "# ## The coefficients\n",
    "# print('Coefficients: \\n', regr.coef_)\n",
    "\n",
    "# ## The mean squared error\n",
    "# print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# ## Explained variance score: 1 is perfect prediction\n",
    "# print('Variance score: %.2f' % r2_score(y_test, y_pred))\n",
    "\n",
    "# ## Plot outputs\n",
    "# plt.scatter(X_test, y_test,  color='black')\n",
    "# plt.plot(X_test, y_pred, color='blue', linewidth=2)\n",
    "\n",
    "# plt.xticks(())\n",
    "# plt.yticks(())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROI ~ ROI | Linear Reg w/ Cond Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def lmplots(df_type,sub_or_group):\n",
    "    #---------------------------------##\n",
    "    #  Display regplots\n",
    "    #---------------------------------##  \n",
    "    ## Uncomment for \"Plot Group Data\"\n",
    "    sns.set()\n",
    "    target_rois=['L_IFG','R_IFG','L_dlPFC','R_dlPFC']\n",
    "    def make_plots(roi,target_rois):    \n",
    "        for region in target_rois:\n",
    "            slope, intercept, r_value, p_value, std_err = \\\n",
    "            stats.linregress(df_type['%s' % roi],df_type['%s' % region])\n",
    "            g=sns.lmplot(x=\"%s\" % roi,y=\"%s\" % region,data=df_type,hue=\"group\",markers=[\"o\", \"x\"])\n",
    "#             g=sns.lmplot(x=\"%s\" % roi,y=\"%s\" % region,data=df_type,hue='cond')\n",
    "            plt.title(\"%s | r = %.2f | p = %s\" % (sub_or_group,r_value,p_value))\n",
    "            g.set_axis_labels('%s' % roi, '%s' % region)\n",
    "            new_title = 'Group'\n",
    "            g._legend.set_title(new_title)\n",
    "            new_labels = ['C', 'P']\n",
    "            for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "            plt.show()\n",
    "        return\n",
    "    make_plots(\"dACC\",target_rois)  \n",
    "    make_plots(\"L_IFG\",target_rois[1:])\n",
    "    make_plots(\"R_IFG\",target_rois[2:])   \n",
    "    make_plots(\"L_dlPFC\",target_rois[3:])\n",
    "    return\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Group Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# lmplots(df,'ALL SUBJS')\n",
    "# lmplots(df_hcs,'CONTROL SUBJS')\n",
    "# lmplots(df_pts,'PSYCHIATRIC SUBJS')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Data by Conditon\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# lmplots(df_I,'INCONGRUENT')\n",
    "# lmplots(df_C,'CONGRUENT')\n",
    "# lmplots(df_I_C,'INCONGRUENT-CONGRUENT')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     lmplots(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot ROI ~ SS var | Linear Reg w/ Cond Hue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def lmplots_ss(df_type,sub_or_group):\n",
    "    ##---------------------------------##\n",
    "    ##  Display regplots\n",
    "    ##---------------------------------##  \n",
    "    sns.set()\n",
    "    target_rois=['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']\n",
    "    def make_plots(ss_var,target_rois):\n",
    "        for region in target_rois:\n",
    "            slope, intercept, r_value, p_value, std_err = \\\n",
    "            stats.linregress(df_type['%s' % ss_var],df_type['%s' % region])\n",
    "            g=sns.lmplot(x=\"%s\" % ss_var,y=\"%s\" % region,data=df_type,hue=\"group\")\n",
    "            plt.title(\"%s | r = %.2f | p = %s\" % (sub_or_group,r_value,p_value))\n",
    "            g.set_axis_labels('%s' % ss_var, '%s' % region)\n",
    "            new_title = 'Group'\n",
    "            g._legend.set_title(new_title)\n",
    "            new_labels = ['C', 'P']\n",
    "            for t, l in zip(g._legend.texts, new_labels): t.set_text(l)\n",
    "            plt.show()\n",
    "        return\n",
    "    make_plots(\"conflict\",target_rois)  \n",
    "    make_plots(\"adapt\",target_rois)\n",
    "    make_plots(\"rt\",target_rois)\n",
    "    return\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Group Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# lmplots_ss(df,'ALL SUBJS')\n",
    "# lmplots_ss(df_hcs,'CONTROL SUBJS')\n",
    "# lmplots_ss(df_pts,'PSYCHIATRIC SUBJS')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# lmplots_ss(df_I_C,'ALL SUBJS | Incongruent-Congruent')\n",
    "# lmplots_ss(df_I,'ALL SUBJS | Incongruent')\n",
    "# lmplots_ss(df_C,'ALL SUBJS | Congruent')\n",
    "# lmplots_ss(df_hcs_I,'CTRL SUBJS I')\n",
    "# lmplots_ss(df_hcs_C,'CTRL SUBJS C')\n",
    "# lmplots_ss(df_pts_I,'PSYCH SUBJS I')\n",
    "# lmplots_ss(df_pts_C,'PSYCH SUBJS C')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     lmplots_ss(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Joint Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def jpd_corr_plots(df_type1,df_type2,sub_or_group):\n",
    "    ##---------------------------------##\n",
    "    ##  Display JPD + correlations\n",
    "    ##---------------------------------## \n",
    "    target_rois=['L_IFG','R_IFG','L_dlPFC','R_dlPFC']\n",
    "    def make_joint_plots(roi,target_rois):   \n",
    "        for region in target_rois:\n",
    "            sns.set()\n",
    "            g = sns.kdeplot(df_type1[\"%s\" % roi],df_type1[\"%s\" % region],\\\n",
    "                    cmap=\"Blues\", shade=True, shade_lowest=False, cbar=True, labels='HCS')\n",
    "            g = sns.kdeplot(df_type2[\"%s\" % roi],df_type2[\"%s\" % region], \\\n",
    "                cmap=\"Oranges\", shade=False, shade_lowest=False, cbar=True, labels='PTS')\n",
    "            plt.legend()\n",
    "            plt.title(\"oranges = patients | blues = controls\")\n",
    "            plt.show()       \n",
    "        return\n",
    "    make_joint_plots(\"dACC\",target_rois)  \n",
    "    make_joint_plots(\"L_IFG\",target_rois[1:])\n",
    "    make_joint_plots(\"R_IFG\",target_rois[2:])   \n",
    "    make_joint_plots(\"L_dlPFC\",target_rois[3:])\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot ALL Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# jpd_corr_plots(df_hcs,df_pts,'ALL SUBJS')\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# jpd_corr_plots(df_hcs_I,df_pts_I,'Incongruent ALL SUBJS')\n",
    "# jpd_corr_plots(df_hcs_C,df_pts_C,'Congruent ALL SUBJS')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joint plots and pair grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pairgrid_plot(df_type,sub_or_group):\n",
    "    sns.set()\n",
    "    sns.axes_style('white')\n",
    "    palette=sns.color_palette(\"Paired\", 2)\n",
    "    vars=[\"dACC\",\"L_IFG\",\"R_IFG\",\"L_dlPFC\",\"R_dlPFC\",\"conflict\",\"adapt\",\"rt\"]\n",
    "#     g = sns.PairGrid(df_type,vars=vars,hue='subject')\n",
    "    g = sns.PairGrid(df_type,vars=vars,hue='cond')\n",
    "    g.map(sns.regplot)\n",
    "    g.add_legend()\n",
    "    plt.title('%s' % sub_or_group)\n",
    "    plt.show()\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot ALL Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# pairgrid_plot(df,'ALL SUBJS')\n",
    "# pairgrid_plot(df_hcs,'CONTROL SUBJS')\n",
    "# pairgrid_plot(df_pts,'PSYCHIATRIC SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# pairgrid_plot(df_I,'Incongruent ALL SUBJS')\n",
    "# pairgrid_plot(df_hcs_I,'Incongruent CONTROL SUBJS')\n",
    "# pairgrid_plot(df_pts_I,'Incongruent PSYCHIATRIC SUBJS')\n",
    "# pairgrid_plot(df_C,'Congruent ALL SUBJS')\n",
    "# pairgrid_plot(df_hcs_C,'Congruent CONTROL SUBJS')\n",
    "# pairgrid_plot(df_pts_C,'Congruent PSYCHIATRIC SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot Individual Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# for subj in SUBJ_LIST:\n",
    "#     df_sub=df.where(df['subject']==subj)\n",
    "#     df_sub=df_sub.dropna()\n",
    "#     pairgrid_plot(df_sub,subj.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def df_dist(regions,df_type,subj_group,behav_vars):\n",
    "    for region in regions:\n",
    "        sns.distplot(df_type['%s' % region],label='%s' % region)\n",
    "    plt.legend()\n",
    "    plt.title(subj_group)\n",
    "    plt.xlabel('ALL ROIs')\n",
    "    plt.show()\n",
    "    for region in regions:\n",
    "        sns.distplot(df_type['%s' % region])\n",
    "        plt.title(subj_group)\n",
    "        plt.show()\n",
    "    for var in variables:\n",
    "        sns.distplot(df_type['%s' % var],label='%s' % var)\n",
    "#         sns.distplot(df_type['%s' % var], kde=False, fit=stats.gamma)\n",
    "    plt.legend()\n",
    "    plt.title(subj_group)\n",
    "    plt.xlabel('ALL Variables')\n",
    "    plt.show()\n",
    "    for var in variables:\n",
    "        sns.distplot(df_type['%s' % var])\n",
    "#         sns.distplot(df_type['%s' % var], kde=False, fit=stats.gamma)\n",
    "        plt.title(subj_group)\n",
    "        plt.show()\n",
    "    return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "## Plot AVERAGED Group Data\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# df_dist(regions,df_I,'Incongruent ALL SUBJS',variables)\n",
    "# df_dist(regions,df_hcs_I,'Incongruent CONTROL SUBJS',variables)\n",
    "# df_dist(regions,df_pts_I,'Incongruent PSYCHIATRIC SUBJS',variables)\n",
    "# df_dist(regions,df_C,'Congruent ALL SUBJS',variables)\n",
    "# df_dist(regions,df_hcs_C,'Congruent CONTROL SUBJS',variables)\n",
    "# df_dist(regions,df_pts_C,'Congruent PSYCHIATRIC SUBJS',variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Mixed Effects Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def mixed_LM(df_type,sub_or_group):\n",
    "#     for beta in ['dACC','L_IFG','R_IFG','L_dlPFC','R_dlPFC']:\n",
    "#         for ss_v in ['conflict','adapt','rt']:\n",
    "#             md = smf.mixedlm('%s ~ %s' % (reg,ss_v),data=df_type,groups=\"group\")\n",
    "#             mdf = md.fit()\n",
    "#             print(mdf.summary())\n",
    "#     return\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "# mixed_LM(df,'ALL SUBJS')\n",
    "# mixed_LM(df_hcs,'CONTROL SUBJS')\n",
    "# mixed_LM(df_pts,'PSYCHIATRIC SUBJS')\n",
    "##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *DEPRECIATED: Modify this section to reflect updated ss model*\n",
    "\n",
    "The MSIT state space model is as follows:\n",
    "\n",
    "$$\n",
    "RT(k) = \\beta_0 + \\beta_1 * Interference + X_{ss}(k)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "X_{ss}(k) = X_{ss}(k - 1) + W\n",
    "$$\n",
    "\n",
    "Interference is 1 if the current trial k is an incongruent trial and 0 if it is a congruent trial."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "##---------------------------------##\n",
    "##----->> SS Notes:\n",
    "##---------------------------------##\n",
    "SS Output:\n",
    "- XSmt = smoothing result - mean\n",
    "- SSmt = smoothing result - variance\n",
    "##---------------------------------##\n",
    "2 state vars - variance, covariance components\n",
    "- XPos = filtering result - mean\n",
    "- SPos = filtering result - variance\n",
    "##---------------------------------##\n",
    "- ML = value of E-step maximization\n",
    "- EYn = prdiction of the Yn\n",
    "- Param = updated model parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
